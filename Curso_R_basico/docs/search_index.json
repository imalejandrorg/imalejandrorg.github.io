[["análisis-de-varianza-anova.html", "Lección 3 Análisis de Varianza (ANOVA) 3.1 Prueba de normalidad 3.2 Prueba de homocedasticidad 3.3 Análisis de varianza (ANOVA de una vía)", " Lección 3 Análisis de Varianza (ANOVA) Para realizar un análisis de varianza o ANOVA es necesario cumplir con ciertos supuestos. Estos supuestos son similares para otro tipo de pruebas y se encuentran descritas en la sigueinte lista: Distribución normal de los datos. Homocedasticidad (varianzas iguales). Datos independientes. La distribución normal y la homocedasticidad son hasta cierto punto flexibles. Sin embargo, el ANOVA es sumamente sentitivo a muestras no independientes. Pese a su nombre, el análisis de varianza en realidad busca diferencias en las medias (\\(\\mu\\)) de las muestras. Antes de hacer el ANOVa debemos buscar una manera de comprobar la distribución normal y la homocedasticidad de los datos. Esto es relativamente sencillo de hacer. 3.1 Prueba de normalidad Una de las pruebas de normalidad más utilizadas es la prueba de Shapiro-Wilk. El resultado de la prueba de Shapiro-Wilk es un valor-p que se puede interpretar de la siguiente manera: Valor-p \\(&lt;\\) 0.01: No normalidad. Valor-p \\(&lt;\\) 0.05: No normalidad. Valor-p \\(\\ge\\) 0.05: Sin evidencia concluyente de no normalidad. Usualmente un valor-p \\(&lt;\\) 0.05 es suficiente para indicar que nuestros datos no se distribuyen de manera normal. Esta base de datos incluye 2 variables, los valores del peso y el tratamiento que recibieron las plantas. Para esta ocasión vamos a trabajar con la base de datos PlantGrowth que viene incluida en R. data(&quot;PlantGrowth&quot;) Vamos a realizar una gráfica de nuestros datos para darnos una idea de su comportamiento. library(ggplot2) ggplot(PlantGrowth) + geom_point(aes(group, weight, color = group)) + xlab(&quot;Grupo&quot;) + ylab(&quot;Peso&quot;) + scale_color_discrete(name = &quot;Tratamientos&quot;, labels = c(&quot;Control&quot;, &quot;Tratamiento 1&quot;, &quot;Tratamiento 2&quot;)) + theme_classic() Figura 3.1: Gráfica con los distintos tratamientos. Otra forma de visualizar los datos es con un boxplot que puede ir dándonos idea más o menos de cómo se distribuyen nuestros datos. library(ggplot2) ggplot(PlantGrowth) + geom_boxplot(aes(group, weight, fill = group)) + xlab(&quot;Grupo&quot;) + ylab(&quot;Peso&quot;) + scale_fill_discrete(name = &quot;Tratamientos&quot;, labels = c(&quot;Control&quot;, &quot;Tratamiento 1&quot;, &quot;Tratamiento 2&quot;)) + theme_classic() Figura 3.2: Graficos de boxplot para visualización de las distribuciones de los datos. Computar la prueba de normalidad de Shapiro-Wilk sumamente sencillo y se hace con la función shapiro_test() de la librería rstatix. Para esto primero tenemos que agrupar nuestros datos por tratamientos con la función group_by() del paquete de dplyr. library(tidyverse) library(rstatix) ## Warning: package &#39;rstatix&#39; was built under R version 4.0.4 ## ## Attaching package: &#39;rstatix&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## filter PlantGrowth %&gt;% group_by(group) %&gt;% shapiro_test(weight) #Agrupamos los datos por tratamiento. ## # A tibble: 3 x 4 ## group variable statistic p ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ctrl weight 0.957 0.747 ## 2 trt1 weight 0.930 0.452 ## 3 trt2 weight 0.941 0.564 Tanto el control como los dos tratamientos tienen un valor-p \\(&gt;\\) 0.05, lo que indica que se distribuyen de manera normal. El estadístico que obtenemos se conoce como \\(W\\) y entre más cercano sea su valor a 1 más evidencia existe de que se trata de datos que se distribuyen de manera normal. Otra opción es realizar la prueba de Shapiro-Wilk con la función integrada en R, de nombre bastante similar, llamada shapiro.test(). Para esta prueba no es necesario agrupar los datos por tratamiento. PlantGrowth$weight %&gt;% shapiro.test ## ## Shapiro-Wilk normality test ## ## data: . ## W = 0.98268, p-value = 0.8915 Como podemos ver, el valor-p = 0.8915, lo que indica que nuestros datos se distribuyen de manera normal. Algo importante a tener en consideración es que para muestras con \\(n &gt; 50\\) es recomendable utilizar otra prueba ya que la prueba de Shapiro-Wilk es sensible a pequeñas desviaciones de la normalidad para muestras grandes. Una alternativa es la utilización de gráficos Q-Q o Q-Q plot. Los gráficos Q-Q nos muestran la correlación que existe entre una muestra dada y la distribución normal. Utilizaremos la librería ggpubr y la función ggqqplot(). library(ggpubr) ## Warning: package &#39;ggpubr&#39; was built under R version 4.0.4 ggqqplot(PlantGrowth$weight) + xlab(&quot;Teórico&quot;) + ylab(&quot;Muestra&quot;) Figura 3.3: Gráfico Q-Q que muestra la distribución normal de datos. Este gráfico nos muestra una distribución normal teórica vs. la de nuestros datos. Como podemos ver, todos los puntos caen dentro del intervalo de confianza al 95% de la recta, lo que quiere decir que nuestros datos se distribuyen de manera normal. Esto confirma los resultados obtenidos con la prueba de Shapiro-Wilk. Otra opción sería ver la gráfica de densidad para identificar la forma de la distribución. ggdensity(PlantGrowth$weight, fill = &quot;lightblue&quot;) + xlab(&quot;Peso&quot;) + ylab(&quot;Densidad&quot;) Figura 3.4: Gráfico de densidad que muestra una ligera forma de campana, lo que indica una distribución normal de los datos. 3.2 Prueba de homocedasticidad Para la prueba de homocedasticidad existen varias aproximaciones. En este caso veremos pruebas estadísticas, ya que existen pruebas que se pueden realizar una vez realizamos el ANOVA. La prueba a utilizar es la prueba de Bartlett, que en R se escribe bartlett.test(). Es una prueba relativamente sencilla de realizar. bartlett.test(weight ~ group, PlantGrowth) ## ## Bartlett test of homogeneity of variances ## ## data: weight by group ## Bartlett&#39;s K-squared = 2.8786, df = 2, p-value = 0.2371 Indicamos que la variable weight va a ser evaluada bajo la variable group. Como resultados tenemos el estadístico Bartlett, los grados de libertad y el valor-p, que en este caso resulto ser valor-p \\(&gt;\\) 0.05 lo que significa que aceptamos la hipótesis de que nuestros datos tienen varianzas iguales. Un valor-p \\(&lt;\\) 0.05 indicaría que nuestros datos NO tienen varianzas iguales. Otra prueba que podemos utilizar que viene en la librería car es la prueba de Levene. Utilizamos la función leveneTest(). library(car) leveneTest(weight ~ group, PlantGrowth, mean) ## Levene&#39;s Test for Homogeneity of Variance (center = mean) ## Df F value Pr(&gt;F) ## group 2 1.237 0.3062 ## 27 En este caso nuestro valor-p es mayor a 0.05 (indicado en el outpot como Pr(&gt;F)) lo que indica que no hay diferencias en las varianzas de nuestras muestras. Es importante que en nuestro último argumento (center) escribamos que queremos que los calculos se realicen con la media (center = mean). Si utilizamos la mediana, haremos una prueba modificada de Levene conocida como prueba de Brown-Forsythe, que es la prueba que realiza por defecto si no escribimos mean. leveneTest(weight ~ group, PlantGrowth) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 1.1192 0.3412 ## 27 Podemos ver que medida de tendencia central utilizó en la consola, después del título de la prueba. Una vez que hemos corroborado que nuestros datos presentan homocedasticidad, distribución normal y sabemos que son independientes, podemos proceder a hacer el ANOVA. 3.3 Análisis de varianza (ANOVA de una vía) Algo importante es que R requiere que las variables predictoras sean clasificadas como grupos de factores. Si corroboramos en nuestros datos de PlantGrowth veremos que efectivamente la variable predictora (el tratamiento) se encuentra como factor. str(PlantGrowth) ## &#39;data.frame&#39;: 30 obs. of 2 variables: ## $ weight: num 4.17 5.58 5.18 6.11 4.5 4.61 5.17 4.53 5.33 5.14 ... ## $ group : Factor w/ 3 levels &quot;ctrl&quot;,&quot;trt1&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... En caso de que nuestros datos no se encuentren como factores podemos transformarlos con la función as.factor() o as_factor(). datos &lt;- as.factor(c(&quot;Tratamiento1&quot;, &quot;Tratamiento2&quot;, &quot;Control&quot;)) str(datos) ## Factor w/ 3 levels &quot;Control&quot;,&quot;Tratamiento1&quot;,..: 2 3 1 Cuando nos referimos a un ANOVA de una vía decimos que solamente consideramos una variable predictora o independiente. También se le conoce como ANOVA de un factor. En este caso, para la base de datos de PlantGrowth solo estamos considerando el tratamiento, por lo tanto lo lógico es hacer un ANOVA de una vía. Sin emabrgo, si además del tratamiento tuvieramos otra variable como la cantidad de luz, podríamos considerar hacer un ANOVA de dos vías. El ANOVA parte de la hipótesis de que todas las muestras vienen de una población con la misma media, es decir \\(H_0\\): Las medias de todas las muestras son iguales: \\(\\mu = \\mu_2 = \\mu_3 = ... = \\mu_n\\). \\(H_A\\): Al menos una de las medias de las muestras es distinta: \\(\\mu_1 \\neq \\mu_n\\). Antes de empezar a hacer el análisis recordemos un poco los fundamentos del ANOVA. Empecemos con cierta notación que nos será útil. \\(k\\) = número de grupos/poblaciones/tratamientos. \\(n_i\\) = número de muestras en el grupo/tratamiento i. \\(x_{ij}\\) = el j-ésimo valor en el i-ésimo grupo/tratamiento. \\(\\overline{x}_i\\) = la media del i-ésimo grupo/tratamiento. \\(s_i\\) = la desviación estándar del i-ésimo grupo/tratamiento. \\(n\\) = el número total de muestras/observaciones independientemente del grupo. \\(\\overline{x}\\) = la media global de todos los grupos/poblaciones/tratamientos independientemente del grupo. El estadístico calculado para el ANOVA se conoce como \\(F_{ratio}\\), ya que es una relación entre dos valores: los cuadrados medios entre grupos (\\(CM_{entre}\\)) y los cuadrados medios dentro de los grupos (\\(MS_{dentro}\\)). \\[\\begin{equation} F_{ratio} = \\frac{CM_{entre}}{CM_{dentro}} \\tag{3.1} \\end{equation}\\] Cada uno de estos términos tiene su propia fórmula. \\[\\begin{equation} CM_{entre} = \\frac{SC_{entre}}{gl_{entre}} \\tag{3.2} \\end{equation}\\] Dónde \\(gl_{entre}\\) hace referencia a los grados de libertad entre grupos y \\(SC_{entre}\\) hace referencia a la suma de cuadrados entre grupos. \\[\\begin{equation} CM_{dentro} = \\frac{SC_{dentro}}{gl_{dentro}} \\tag{3.3} \\end{equation}\\] Dónde \\(gl_{dentro}\\) hace referencia a los grados de libertad dentro de los grupos** y \\(SC_{dentro}\\) hace referencia a la suma de cuadrados dentro de los grupos. Para calcular la suma de cuadrados total usamos la siguiente ecuación. La suma de cuadrados total hace referencia a la variación de todos los datos respecto de la media global (\\(\\overline{x}\\)). \\[\\begin{equation} SC_{total} = \\sum_{i = 1}^{k}\\sum_{j = 1}^{n_i}(x_{ij}-\\overline{x})^2 = SC_{entre} + SC_{dentro} \\tag{3.4} \\end{equation}\\] Pues esta suma de cuadrados total está compuesta de dos valores: la suma de cuadrados entre grupos (\\(SC_{entre}\\)) y la suma de cuadrados dentro de los grupos (\\(SC_{dentro}\\)) aunque también se le conoce como el error o los residuales. Para calcular la suma de cuadrados entre grupos usamos la siguiente ecuación. Este valor hace referencia a la variación de las medias de cada grupo (\\(\\overline{x}_i\\)) cada grupo respecto de la media global (\\(\\overline{x}\\)). \\[\\begin{equation} SC_{entre} = \\sum_{i = 1}^{k}n_{i}(\\overline{x}_{i} - \\overline{x})^2 \\tag{3.5} \\end{equation}\\] Para calcular la suma de cuadrados dentro de los grupos usamos la siguiente ecuación. Este valor hace referencia a la variación de cada muestra u observación dentro de un grupo respecto de la media de ese grupo (\\(\\overline{x}_i\\)). \\[\\begin{equation} SC_{dentro} = \\sum_{i = 1}^{k}\\sum_{j = 1}^{n_i}(x_{ij} - \\overline{x}_{i})^2 = \\sum_{i = 1}^{k}(n_i - 1)s_i^2 = SC_{total} - SC_{entre} \\tag{3.6} \\end{equation}\\] El calculo de los grados de libertad es algo relativamente sencillo y se puede hacer de la siguiente manera. Para los grados de libertad entre grupos: \\[\\begin{equation} gl_{entre} = k - 1 \\tag{3.7} \\end{equation}\\] Para los grados de libertad dentro de los grupos: \\[\\begin{equation} gl_{dentro} = n - k \\tag{3.8} \\end{equation}\\] Para los grados de libertad totales: \\[\\begin{equation} gl_{total} = n - 1 \\tag{3.9} \\end{equation}\\] Algo recomendado de hacer es construir una tabla con cada uno de los pasos a seguir con sus respectivas fórmulas. Los resultados que se presenta el ANOVA en R tiene un formato similar. Tabla 3.1: Tabla de ANOVA Fuentes gl SC CM F_ratio Entre grupos (Tratamientos) \\(k - 1\\) \\(\\sum_{i = 1}^{k}n_{i}(\\overline{x}_{i} - \\overline{x})^2\\) \\(\\frac{SC_{entre}}{gl_{entre}}\\) \\(\\frac{CM_{entre}}{CM_{dentro}}\\) Dentro de grupos (Residuales) \\(n - k\\) \\(\\sum_{i = 1}^{k}\\sum_{j = 1}^{n_i}(x_{ij} - \\overline{x}_{i})^2\\) \\(\\frac{SC_{dentro}}{gl_{dentro}}\\) Total \\(n - 1\\) \\(\\sum_{i = 1}^{k}\\sum_{j = 1}^{n_i}(x_{ij}-\\overline{x})^2\\) "]]
