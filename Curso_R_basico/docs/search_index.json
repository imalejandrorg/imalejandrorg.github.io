[["index.html", "Curso de R básico Lección 1 Requisitos 1.1 Descarga de R y RStudio", " Curso de R básico Alejandro Ruiz-García 15/3/2021 Lección 1 Requisitos Antes de comenzar con el curso es necesario que descarguemos ciertos programas entre ellos están incluidos R y RStudio. 1.1 Descarga de R y RStudio Tenemos que distinguir entre R y RStudio. Como tal, R es el lenguaje de programación y RStudio es el ambiente de trabajo donde utilizamos este lenguaje de programación. Para descargar R podemos acceder al link de esta página. Una vez descargado e instalado R, procedemos a descargar RStudio desde esta página. Con estas herramientas podemos comenzar a trabajar en RStudio. "],["introducción-a-r.html", "Lección 2 Introducción a R 2.1 Interfaz 2.2 Creando nuestro primer proyecto 2.3 Objetos y variables 2.4 Instalar paquetes 2.5 Importar datos a R 2.6 Comentarios 2.7 Exportar datos 2.8 Pedir ayuda", " Lección 2 Introducción a R En esta lección veremos las nociones más básicas de R y RStudio, cómo escribir tablas, cómo importar datos, entre otras cosas. Hola saludos a la Kmi. 2.1 Interfaz R Studio cuenta con 4 ventanas esenciales: La consola, que es donde se ejecutan los comandos y se visualizan los outputs de nuestros análisis. Los scripts, que corresponde a la ventana superior izquierda. No solamente se visualizan scripts, también se pueden trabajar otros formatos, aunque generalmente será donde nosotros escribamos los comandos que la consola va a ejecutar. El Envirnoment y el History que corresponden a la ventana superior derecha, aunque también cuenta con otras herramientas útiles como Build y Git que se utilizan en cuestiones más avanzadas. Los Files, Packages y Plots así como la ventana de Help que corresponden a la esquina inferior derecha. Básicamente estas son las 4 pestañas de esta ventana que estaremos utilizando. Figura 2.1: Interfaz de RStudio Adicionalmente, en la ventana de Tools -&gt; Global Options -&gt; Appearance podemos configurar los colores de nuestra interfaz, el tamaño de la fuente, el zoom, el tema del editor y la tipografía. Figura 2.2: Para abrir las opciones globales nos vamos a Tools -&gt; Global Options. Figura 2.3: Ventana de Appearance dentro de las Opciones Globales de RStudio Personalmente encuentro los colores oscuros más cómodos para trabajar, por eso elegí el tema Material. 2.2 Creando nuestro primer proyecto Una vez que nos familiarizamos con la interfaz, es momento de crear nuestro primer proyecto. Para esto, debemos dar clic en File -&gt; New Project para que nos aparezca una ventana como la siguiente. Figura 2.4: Ventana para crear un nuevo proyecto a partir de distintas opciones: Nuevo directorio, directorio existente y versión de control. Creamos un nuevo directorio que se guarda por defecto en la carpeta de Documentos de nuestro ordenador. SE RECOMIENDA NO DEJAR ESPACIOS EN EL NOMBRE. En su lugar, podemos utilizar guión bajo (_), el símbolo de menos (-) o un punto (.). Una vez creado nuestro proyecto, vamos a crear un nuevo archivo script tecleando Ctrl + Shift + N. Deberíamos tener un ambiente de trabajo más o menos así. Figura 2.5: Ventana con el ambiente de trabajo básico en RStudio. Otra recomendación es guardar nuestro script en la misma carpeta del proyecto, así como las bases de datos y demás archivos que vayamos a utilizar. Para saber cuál es la carpeta de nuestro proyecto, podemos teclear el siguiente comando en la consola. getwd() ## [1] &quot;O:/Tesis/R/Webpage/imalejandrorg.github.io/Curso_R_basico&quot; Para cambiar el directorio de trabajo, simplemente tecleamos en la consola la siguiente función. setwd(&quot;O:/Documentos/R_Basico&quot;) getwd() ## [1] &quot;O:/Documentos/R_Basico&quot; De esta manera cambiamos el directorio de nuestro proyecto actual y sabemos en qué carpeta ingresar nuestros archivos. Para guardar nuestro script simplemente hacemos clic en icono del disquete o con las teclas Ctrl + S. Recuerda que es recomendable guardar el script en la misma carpeta que nuestro proyecto. 2.3 Objetos y variables Para que un comando que queramos ejecutar permanezca almacenado, debemos asignar un nombre al resultado. La manera en la que R hace esto es a través de los símbolos &lt;- o = (cuyo atajo de escritura es Alt + -). Por ejemplo, si queremos realizar una suma de 5 + 5 pondríamos el siguiente código en la consola. 5 + 5 ## [1] 10 Sin embargo, si queremos almacenar este resultado necesitamos nombrar a una variable con este resultado. Por ejemplo, una variable llamada suma. suma &lt;- 5 + 5 suma ## [1] 10 Como podemos ver en ambos casos obtenemos los mismos resultados. Sin embargo, en el segundo caso encontraremos una variable llamada suma en nuestro Environment en el panel superior derecho. Figura 2.6: Panel Environment en el cual podremos encontrar las variables que vayamos generando. En caso de que estemos interesados en asignar valores categóricos, estos deben estar encomillados. letraA &lt;- &quot;A&quot; De nuevo se agregará esta variable a nuestro Environment. Figura 2.7: Tras definir la variable A esta se suma a la ventana de Environment. Para corroborar el tipo de dato que tenemos podemos utilizar la función class(x) donde x es el nombre de nuestra variable. class(letraA) ## [1] &quot;character&quot; class(suma) ## [1] &quot;numeric&quot; Para los análisis de datos de naturaleza biológica normalmente se trabaja con matrices de datos con múltiples caracteres tanto categóricos como cuantitativos, que en R corresponde a un data frame. Por ejemplo, los datos de una matriz llamada dune del paquete vegan corresponde a una matriz de datos. data(&quot;dune&quot;) class(dune) ## [1] &quot;data.frame&quot; Achimill Agrostol Airaprae Alopgeni Anthodor Bellpere Bromhord Chenalbu Cirsarve Comapalu Eleopalu Elymrepe Empenigr Hyporadi Juncarti Juncbufo Lolipere Planlanc Poaprat Poatriv Ranuflam Rumeacet Sagiproc Salirepe Scorautu Trifprat Trifrepe Vicilath Bracruta Callcusp 1 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 7 0 4 2 0 0 0 0 0 0 0 0 0 0 3 0 0 2 0 3 4 0 0 0 0 4 0 0 0 0 5 0 4 7 0 0 0 0 5 0 5 0 0 0 0 4 0 7 0 2 0 0 0 0 0 4 0 0 0 0 6 0 5 6 0 0 0 0 2 0 2 0 2 0 0 8 0 2 0 2 3 0 2 0 0 4 0 0 0 0 5 0 4 5 0 0 5 0 2 0 1 0 2 0 2 0 0 0 4 2 2 0 0 0 0 4 0 0 0 0 2 5 2 6 0 5 0 0 3 2 2 0 2 0 2 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 6 5 3 4 0 6 0 0 3 5 5 0 6 0 2 0 0 0 2 0 2 0 0 0 0 0 0 0 0 2 6 5 4 5 0 3 0 0 3 2 2 0 2 0 0 4 0 5 0 0 0 0 0 0 4 0 0 0 4 0 4 0 4 4 2 0 2 0 3 0 2 0 2 0 0 3 0 3 0 0 0 0 0 0 0 6 0 0 4 4 2 0 4 5 0 2 2 0 2 0 3 0 2 0 4 0 0 0 4 2 4 0 0 0 0 0 0 0 0 0 6 3 4 4 0 0 0 0 3 0 6 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 7 3 4 0 0 0 2 0 5 0 3 2 4 0 0 4 0 8 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 4 0 2 4 0 2 0 3 0 4 0 0 5 0 5 0 0 0 1 0 0 0 0 0 0 0 3 0 0 2 9 2 0 2 0 2 0 2 0 0 0 0 4 0 0 0 0 0 0 0 2 4 0 0 0 0 0 0 0 0 0 2 0 0 0 2 0 6 0 0 4 0 4 0 0 0 0 0 0 0 2 5 0 0 0 3 0 0 0 0 0 2 0 0 0 2 0 1 0 4 0 0 7 0 4 0 0 0 0 0 0 8 0 0 0 3 0 0 0 0 2 2 0 0 0 0 0 0 0 4 3 2 0 2 0 4 0 0 0 0 0 0 0 0 2 0 0 0 2 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 2 3 3 0 0 0 0 3 5 0 2 1 6 0 0 0 3 0 4 0 0 0 0 0 0 0 2 5 0 0 0 0 0 0 0 0 3 3 6 0 2 0 3 0 0 5 0 0 0 0 0 0 0 0 4 0 0 0 4 0 0 0 0 0 4 0 0 5 2 0 0 0 4 3 2.4 Instalar paquetes Una de las herramientas más útiles de R es la instalación de paquetes. No tenemos la necesidad de escribir nuestras propias funciones cada que queramos realizar un análisis. En su lugar, bajamos e instalamos paquetes que nos sirven para ciertas funciones. Por ejemplo, uno de los paquetes más utilizados es el de vegan, útil para realizar análisis ecológicos. Para instalar los paquetes escribimos la siguiente función en la consola. install.packages(&quot;vegan&quot;) Tenemos que conocer el nombre exacto del paquete, en este caso, vegan está escrito con una v minúscula. Tenemos que entender que instalar un paquete no es lo mismo que llamarlo. Para esto último utilizamos la siguiente función. library(vegan) Vemos que en esta ocasión llamamos al paquete sin necesidad de poner el entrecomillado. En ocasiones la función install.package() puede arrojarnos error. Una alternativa es utilizar la ventana de Packages del panel inferior derecho. Figura 2.8: Ventana de Packages donde podremos encontrar los paquetes instalados. Damos clic en Install y escribimos el nombre del paquete. Figura 2.9: Al hacer clic sobre el botón Install en la ventana de Packages aparece esta pequeña ventana donde podremos buscar la librería deseada. Nos irán apareciendo opciones con el nombre del paquete de interés. Lo seleccionamos y damos clic en Install. Figura 2.10: En este caso, solo con escribir las primeras letras del paquete deseado se despliega una lista de librerías con nombres similares. 2.5 Importar datos a R La mayor parte del tiempo lo que queremos hacer es importar nuestros propios datos a R. En este caso utilizaremos las matrices de datos presentadas en el libro de Palacio et al. (2020). Utilizaremos una base de datos de aves del capítulo 6 del libro de Palacio et al. (2020). Descargar: Aves.txt Una vez que tenemos nuestra base de datos en la carpeta de nuestro proyecto, la importamos a través de la función read.table(). Aves &lt;- read.table(&quot;Aves.txt&quot;, header = TRUE) View(Aves) sitio estacion ambiente agebad amabra rupmag spimag chlluc colmel patpic cycguj elapar furruf geoaeq ictcay lepang mimsat molbon myimac myimon pacpol phastr pitsul poldum poomel rossoc sicfla siclut spocae synspi troaed turruf viroli zenaur zoncap 2 inv bosque 1 0 0 0 0 2 2 1 0 6 1 1 1 1 0 0 0 0 0 2 0 0 1 0 0 0 0 5 3 0 2 5 2 oto bosque 1 0 1 0 0 3 2 0 0 2 0 0 2 5 0 0 0 0 0 3 0 0 1 0 0 0 0 3 4 0 1 0 2 pri bosque 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 4 0 1 6 2 ver bosque 1 0 0 0 0 3 0 0 1 6 0 0 4 0 0 0 0 1 1 6 0 0 0 0 0 0 0 1 1 0 8 2 3 inv arbustal 1 0 0 0 0 1 0 0 0 6 0 0 1 0 3 0 0 0 1 2 0 0 3 0 0 0 2 6 3 0 2 6 3 oto arbustal 0 0 0 0 0 0 0 0 0 8 0 0 2 0 0 0 0 0 1 3 0 0 3 0 0 0 0 3 6 0 1 1 3 pri arbustal 0 0 0 0 0 2 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 4 3 3 ver arbustal 3 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 5 4 4 inv arbustal 8 0 0 10 0 0 0 0 0 1 2 2 1 0 1 0 14 0 2 1 0 2 0 0 0 0 1 3 1 0 4 6 4 oto arbustal 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 3 3 0 0 0 0 0 4 3 0 0 1 4 pri arbustal 0 0 0 0 0 0 0 0 0 0 3 0 0 0 2 0 0 0 1 2 0 0 0 0 4 0 0 4 1 0 1 4 4 ver arbustal 1 0 0 0 0 0 0 0 0 3 1 0 0 0 0 1 0 0 1 2 0 0 0 0 0 3 2 2 0 0 0 4 5 inv bosque 0 0 0 0 0 3 2 3 0 4 1 2 1 0 1 0 0 0 0 9 0 0 0 0 0 0 0 2 0 0 2 3 5 oto bosque 37 0 2 0 0 2 2 0 0 2 0 0 1 0 0 0 0 0 0 3 2 0 0 0 0 0 0 3 2 0 0 3 5 pri bosque 0 0 0 1 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 1 1 4 5 ver bosque 10 0 2 0 0 2 0 2 2 0 0 0 0 0 0 1 0 3 0 5 0 0 0 0 0 0 1 1 2 2 1 5 6 inv bosque 0 0 5 0 0 1 2 1 0 4 0 0 1 0 0 0 0 0 0 8 2 0 0 0 0 0 0 0 3 0 4 6 6 oto bosque 0 1 4 0 0 0 2 0 0 3 0 0 1 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 2 0 6 pri bosque 2 0 2 0 0 0 0 1 4 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 2 2 0 3 6 ver bosque 0 4 3 0 1 1 0 0 2 1 0 0 1 0 0 4 0 4 0 1 0 0 0 0 0 0 0 0 1 1 4 3 7 inv bosque 0 0 1 0 1 0 6 0 2 0 0 1 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 16 0 4 2 7 oto bosque 0 0 0 0 0 1 2 1 0 2 0 2 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 3 0 1 0 7 pri bosque 0 0 1 0 0 0 0 0 3 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 2 2 3 7 ver bosque 1 0 0 0 0 1 7 0 3 2 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 5 2 8 inv arbustal 0 0 0 0 0 0 0 2 0 1 1 0 0 2 2 0 0 0 0 3 0 0 1 2 2 0 0 1 1 0 3 9 8 oto arbustal 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 3 8 pri arbustal 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 4 0 0 0 4 2 1 0 1 0 0 0 8 8 ver arbustal 0 0 0 0 1 0 0 0 2 2 0 0 1 0 0 0 0 0 0 2 1 0 0 0 0 7 1 4 4 0 0 5 9 inv arbustal 0 0 0 0 0 4 0 0 0 0 0 0 0 0 1 0 3 0 0 0 1 1 0 0 4 0 0 5 1 0 2 13 9 oto arbustal 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 6 0 1 2 9 pri arbustal 0 0 0 0 0 0 0 0 0 0 3 0 0 0 1 0 0 0 0 2 0 0 0 0 5 0 0 0 1 0 0 6 9 ver arbustal 3 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 0 0 0 3 11 6 1 2 0 0 0 31 10 inv arbustal 0 0 0 1 0 0 0 0 0 0 1 0 2 0 8 0 0 0 2 4 0 0 0 0 3 0 1 0 1 0 1 14 10 oto arbustal 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 3 0 0 1 0 0 0 3 0 4 0 0 7 10 pri arbustal 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 11 10 ver arbustal 1 0 0 0 0 1 0 0 0 7 2 0 0 0 0 0 0 0 0 2 0 0 0 0 3 8 1 2 0 0 0 12 También podemos importar archivos .csv utilizando la función read.csv(). Aves_csv &lt;- read.csv(&quot;Aves.csv&quot;, header = TRUE) Así obtendríamos la misma tabla anterior. En caso de que queramos leer archivos excel, podemos hacerlo utilizando la librería readxl. En caso de ya tener instalado el paquete no es necesario que pongan la función install.packages(\"readxl\"), al ya tenerlo instalado yo omití esta parte poniéndole el símbolo de gato #. #install.packages(&quot;readxl&quot;) library(readxl) Aves_xlsx &lt;- read_excel(&quot;Aves.xlsx&quot;) Estas tres formas de importar los datos nos producen la misma matriz. Sin embargo podemos ver que la clase del archivo importado desde excel pertenece a una subclase de los archivos de tipo data frame llamada tibble. Sin embargo, se recomienda que se cambie el tipo de archivo a solamente data.frame. Para hacer esto podemos escribir el siguiente código Aves_xlsx &lt;- data.frame(Aves_xlsx) class(Aves_xlsx) ## [1] &quot;data.frame&quot; Básicamente le estamos diciendo a R que escriba un data frame con el mismo nombre que el data frame de subtipo tibble. De esta manera sobrescribimos el primer archivo y mantenemos limpio nuestro espacio de trabajo. También se puede importar desde el botón Import Dataset que aparece en la ventana de nuestro Environment. Figura 2.11: En el panel Environment podemos hacer clic sobre la ventanaImport Dataset para importar archivos de distintos formatos. De igual manera se recomienda copiar el código al script para saber exactamente qué hacemos. 2.6 Comentarios Algo muy útil que podemos agregar a nuestro código o script son los comentarios. Estos pueden ayudarnos a recordar qué realiza alguna línea de código o alguna función o argumento en particular. La manera en la que agregamos comentarios es con el símbolo de gato #. #Esta función sirve para importar archivos. Aves &lt;- read.table(&quot;Aves.txt&quot;, header = TRUE) Podemos ver como al poner un # antes de una línea de código esta cambia a color gris. Lo que sea que realice esta línea no será leída. 2.7 Exportar datos En algunas ocasiones queremos trabajar con otro software o queremos exportar nuestra tabla modificada a Excel. Para hacer esto, utilizamos la función write.table(), por ejemplo. #Filtramos nuestro archivo para tener solo las abundancias. Abun &lt;- Aves[,4:35] #Exportamos nuestro archivo en formato .csv write.table(Abun, file = &quot;Abundancias.csv&quot;, sep = &quot;,&quot;, row.names = FALSE) De esta manera omitimos los nombres de la columnas y de las filas, además especificamos que queremos un documento en formato .csv, y que la separación sea por comas. Si no especificamos la ruta, guardaremos nuestro archivo en nuestro directorio de trabajo, si queremos guardar el archivo en un directorio específico, tendremos que dar la ruta antes de poner el nombre. write.table(Abun, file = &quot;O:/Documentos/R_Basico/Lección_1/Abundancias.csv&quot;, sep = &quot;,&quot;, row.names = FALSE) Como podemos ver, el archivo fue escrito en la dirección indicada. Figura 2.12: Dirección a en la cual hemos decidido guardar el archivo Abundancias.csv. Figura 2.13: Archivo Abundancias.csv visto en Excel. 2.8 Pedir ayuda En caso de que no sepamos que argumentos van en alguna función, podemos pedir ayuda en la consola utilizando el símbolo de interrogación ? seguido de la función sobre la cuál tengamos una duda. ?specaccum Cuando nosotros escribimos esto, se abrirá la ventana de Help en el panel inferior derecho y nos mostrará una pequeña descripción de la función, así como sus usos y qué argumentos utilizar. En ocasiones incluso podemos encontrar ejemplos. Figura 2.14: Ventana de ayuda en la pestaña Help para la función que en este caso fue ?specaccum. References Palacio, F. X., Apodaca, M. J., &amp; Crisci, J. V. (2020). Análisis multivariado para datos biológicos. Teoría y su aplicación utilizando el lenguaje r. Fundación Azara. "],["estadística-descriptiva.html", "Lección 3 Estadística descriptiva 3.1 Medidas de tendencia central 3.2 Medidas de dispersión 3.3 Medidas de posición relativa 3.4 El uso de la librería dplyr", " Lección 3 Estadística descriptiva En esta lección veremos las nociones básicas de estadística descriptiva haciendo uso de R y RStudio. Veremos medidas de tendencia central como la media, mediana y moda, medidas de dispersión como el rango o la desviación estándar y medidas de posición relativa como los valores Z. 3.1 Medidas de tendencia central Sirven para describir los valores del centro o valores medios de algún conjunto de datos. Las tres medidas de tendencia central más utilizadas son: media, mediana y moda. 3.1.1 Media Mide el promedio del valor de nuestros datos. Se calcula como la suma de los valores de las observaciones dividida entre el número de observaciones. Es representada como \\(\\overline{x}\\) (pronunciado \\(x\\) barra) para datos muestrales y \\(\\mu\\) (pronunciado mu) para datos poblacionales. Para obtener la media muestral utilizamos la ecuación (3.1) y para obtener la media poblacional se utiliza la ecuación (3.2). \\[\\begin{equation} \\overline{x} = \\frac{\\sum_{i = 1}^{n}{x_i}}{n} \\tag{3.1} \\end{equation}\\] \\[\\begin{equation} \\mu = \\frac{\\sum_{i = 1}^{N}{x_i}}{N} \\tag{3.2} \\end{equation}\\] Donde \\(\\sum_{i=1}^{n}{x_i}\\) y \\(\\sum_{i=1}^{N}{x_i}\\) representan la sumatoria de los valores de todas nuestras observaciones; \\(n\\) y \\(N\\) representan el número de valores de datos en una muestra y el número de valores totales en una población, respectivamente. Propiedades importantes de la media: No es un estadístico robusto, ya que es sensible a valores extremadamente grandes o pequeños. Utiliza todos los datos disponibles. Las medias muestrales (\\(\\overline{x}\\)) de una población tienden a variar menos que otras medidas. 3.1.1.1 Media en R El calculo de la media en R es algo sencillo. Para esto, utilizamos la función mean(). Ejemplo: En un experimento se administraron distintos tratamientos a un grupo de plantas y se midió el peso seco de todas ellas. Supongamos que queremos saber cuál fue la media global para todos los pesos (independientemente del tratamiento). Se utilizará la base de datos PlantGrowth para este ejemplo. data(&quot;PlantGrowth&quot;) Es importante que conozcamos los datos que incluye nuestra matriz. En este caso tenemos dos columnas, weight que hace referencia al peso seco y group que hace referencia al tratamiento. Para sacar la media global (independiente del tratamiento) simplemente escribimos la función mean() y hacemos referencia al peso con el símbolo $. mean(PlantGrowth$weight) ## [1] 5.073 Lo que nos arroja una media de 5.073. Ahora en caso de que quisiéramos sacar la media de por cada uno de los tratamientos tenemos que usar filtros y agrupaciones, para esto podemos utilizar la librería dplyr que viene incluida en el paquete de tidyverse. Vamos a usar el pipeline %&gt;% de dplyr para hacer varias operaciones en cadena: 1) Utilizamos la función group_by(group) para agrupar nuestros datos por el tipo de tratamiento; 2) utilizamos la función summarise(Media = mean(weight), n = n()) para indicar que saque la media de nuestro datos YA agrupados y el número de observaciones de cada grupo. library(tidyverse) resumen &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% summarise(Media = mean(weight), n = n()) resumen ## # A tibble: 3 x 3 ## group Media n ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 ctrl 5.03 10 ## 2 trt1 4.66 10 ## 3 trt2 5.53 10 Al final obtenemos una matriz nueva con 3 columnas: tipo de tratamiento, media para cada tratamiento y número de observaciones para cada tipo de tratamiento. 3.1.2 Mediana Es el valor que se encuentra justo por la mitad de la distribución de nuestros datos. Se respresenta por el símbolo \\(\\tilde{x}\\) (pronunciado \\(x\\) tilde). \\[ 1, 2, 3, 4, 5 \\] Para el conjunto de datos anteriores la mediana es igual al número 3 que se encuentra justo por la mitad de los datos. En caso de tener un número par de observaciones, la mediana se puede calcular como un promedio de los dos valores centrales. Por ejemplo. \\[ 5, 6, 7, 8, 9, 10 \\] Para este caso nuestros valores centrales son 7 y 8. Estos simplemente se promedian. \\[ \\tilde{x} = \\frac{7 + 8}{2} = 7.5 \\] Propiedades importantes de la mediana: No cambia al añadir valores extremos por lo que se le considera un estadístico robusto. No utiliza todo el conjunto de datos. 3.1.2.1 Mediana en R Para el calculo de la mediana se utiliza la función median(). Ejemplo: Supongamos que con los datos del ejemplo anterior queremos ahora calcular la mediana global y la mediana para cada uno de nuestros tratamientos. median(PlantGrowth$weight) ## [1] 5.155 El valor obtenido es de 5.155. De manera similar podemos calcular la mediana para cada uno de nuestros datos utilizando dplyr. resumen &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% summarise(Mediana = median(weight), n = n()) resumen ## # A tibble: 3 x 3 ## group Mediana n ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 ctrl 5.15 10 ## 2 trt1 4.55 10 ## 3 trt2 5.44 10 Si lo deséamos, podemos obtener la media y la mediana en una misma tabla. resumen &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% summarise(Media = mean(weight), Mediana = median(weight), n = n()) resumen ## # A tibble: 3 x 4 ## group Media Mediana n ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 ctrl 5.03 5.15 10 ## 2 trt1 4.66 4.55 10 ## 3 trt2 5.53 5.44 10 3.1.3 Moda Es el valor que más se repite en un conjunto de datos. Propiedades importantes de la moda: Se puede aplicar a datos cualitativos. Puede existir una moda (unimodal), dos modas (bimodal), múltiples modas (multimodal) o ninguna moda. Sin embargo, casi no se utiliza en estadística y por lo mismo no hablaremos más de ella. Como tal no existe una función en R que calcule la moda pero en varias páginas y foros como StackOverflow se pueden encontrar scripts para su calculo. 3.2 Medidas de dispersión A diferencia de los estadísticos de tendencia central, los estadísticos de dispersión se basan en cómo se distribuyen los datos y qué tan esparcidos están. Las medidas que veremos son: rango y desviación estándar. 3.2.1 Rango Se utiliza la función range(). Ejemplo: Queremos calcular el rango de las observaciones de la base de datos de plantas que utilizamos en la sección de medidas de tendencia central. range(PlantGrowth$weight) ## [1] 3.59 6.31 Esto nos da como resultado el valor máximo y el valor mínimo pero no nos dice cuál es el valor de nuestro rango. Podríamos hacer una operación simple para su calculo o utilizar las funciones max() y min(). max(PlantGrowth$weight) - min(PlantGrowth$weight) ## [1] 2.72 Como podemos ver el rango es de 2.72 ya que la diferencia entre 6.31 y 3.59 corresponde a este vakir, Para sacar el valor máximo y mínimo de cada uno de los tratamientos podemos utilizar el paquete de dplyr y la función group_by(). resumen &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% summarise(Rango = max(weight) - min(weight), n = n()) resumen ## # A tibble: 3 x 3 ## group Rango n ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 ctrl 1.94 10 ## 2 trt1 2.44 10 ## 3 trt2 1.39 10 Igualmente, podemos agregar las medidas de tendencia central. resumen &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% summarise(Rango = max(weight) - min(weight), Media = mean(weight), Mediana = median(weight), n = n()) resumen ## # A tibble: 3 x 5 ## group Rango Media Mediana n ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 ctrl 1.94 5.03 5.15 10 ## 2 trt1 2.44 4.66 4.55 10 ## 3 trt2 1.39 5.53 5.44 10 3.2.2 Desviación estándar Mide qué tanto se desvían los valores de los datos de la media. Es representada por el símbolo \\(s\\) para datos muestrales y se calcula con la ecuación (3.3) y \\(\\sigma\\) para datos poblacionales y se calcula a partir de la ecuación (3.4). \\[\\begin{equation} s = \\sqrt{\\frac{\\sum_{i = 1}^{n}( {x_i-\\overline{x} ) ^2}}{n-1}} \\tag{3.3} \\end{equation}\\] \\[\\begin{equation} \\sigma = \\sqrt{\\frac{\\sum_{i = 1}^{n}( {x_i-\\overline{x} ) ^2}}{N}} \\tag{3.4} \\end{equation}\\] Donde \\(\\sum_{i = 1}^{n}({x_i-\\overline{x})^2}\\) es igual al valor cada observación menos la media, elevado al cuadrado, \\({n-1}\\) corresponde a los grados de libertad que tenemos para el cálculo de la desviación estándar y \\(N\\) es el número total de la población. Propiedades importantes de la desviación estándar: Nunca tiene un valor negativo. Mayor valor de \\(s\\) indica mayor variación en los datos. Puede aumentar considerablemente con valores atípicos, es decir, no es robusta. Las unidades de la desviación estándar son iguales a las unidades de los datos originales. 3.2.2.1 Desviación estándar en R Se utiliza la función sd(). Ejemplo: Queremos calcular la desviación estándar de las observaciones de la base de datos de plantas que utilizamos en la sección del rango. sd(PlantGrowth$weight) ## [1] 0.7011918 Obtenemos una desviación estándar de 0.7011918 para todo el conjunto de datos. En caso de querer calcular la desviación estándar de cada tratamiento utilizamos el paquete de dplyr y group_by(). resumen &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% summarise(SD = sd(weight)) resumen ## # A tibble: 3 x 2 ## group SD ## &lt;fct&gt; &lt;dbl&gt; ## 1 ctrl 0.583 ## 2 trt1 0.794 ## 3 trt2 0.443 Y de nueva cuenta, podemos agregar el resto de estadísticos descriptivos que hemos visto hasta ahora. resumen &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% summarise(SD = sd(weight), Rango = max(weight) - min(weight), Media = mean(weight), Mediana = median(weight), n = n()) resumen ## # A tibble: 3 x 6 ## group SD Rango Media Mediana n ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 ctrl 0.583 1.94 5.03 5.15 10 ## 2 trt1 0.794 2.44 4.66 4.55 10 ## 3 trt2 0.443 1.39 5.53 5.44 10 En esta tabla podemos ver todos lo estadísticos que hemos calculado hasta ahora. Algo importante a tener en cuenta es que sd() calcula la desviación estandar muestral \\(s\\), no la poblacional \\(\\sigma\\). Para calcular \\(\\sigma\\) necesitamos multiplicar el resultado obtenido por \\(\\sqrt\\frac{N-1}{N}\\). sd(PlantGrowth$weight)*(sqrt((length(PlantGrowth$weight)-1)/length(PlantGrowth$weight))) ## [1] 0.6894063 En caso de que se utilice frecuentemente la \\(\\sigma\\) se puede definir la función de la siguiente manera. sd.p = function(x){sd(x)*sqrt((length(x)-1)/length(x))} Para calcular la varianza \\(s^2\\), simplemente elevamos al cuadrado el valor obtenido de la desviación estándar, se calcula con la siguiente ecuación (3.5). \\[\\begin{equation} Varianza = {s}^2 \\tag{3.5} \\end{equation}\\] sd(PlantGrowth$weight)^2 ## [1] 0.49167 Propiedades importantes de la varianza: Las unidades están elevadas al cuadrado. No es un estadístico robusto. Nunca tiene valores negativos. Otro estadístico que nos puede interesare es el coeficiente de variación que se obtiene a partir de la ecuación (3.6). \\[\\begin{equation} CV = \\frac{S}{\\overline{x}}*100 \\tag{3.6} \\end{equation}\\] Para su calculo simplemente utilizamos las funciones previamente aprendidas. sd(PlantGrowth$weight)/mean(PlantGrowth$weight)*100 ## [1] 13.82204 Nusetro resultado es 13.82204%. Este es el coeficiente de variación para todos los datos. De nueva cuenta, todo esto puede ser integrado en una sola tabla con la función summarise()del paquete dplyr. resumen &lt;- resumen &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% summarise(CV = sd(weight)/mean(weight)*100, Varianza = sd(weight)^2, SD = sd(weight), Rango = max(weight) - min(weight), Media = mean(weight), Mediana = median(weight), n = n()) resumen ## # A tibble: 3 x 8 ## group CV Varianza SD Rango Media Mediana n ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 ctrl 11.6 0.340 0.583 1.94 5.03 5.15 10 ## 2 trt1 17.0 0.630 0.794 2.44 4.66 4.55 10 ## 3 trt2 8.01 0.196 0.443 1.39 5.53 5.44 10 3.3 Medidas de posición relativa Indican la posición relativa de los datos con respecto de los demás datos. Algunas de las más usadas son: valores Z, frecuencia absoluta, frecuencia relativa y cuartiles. 3.3.1 Valores Z Se obtienen al estandarizar los valores de nuestros datos. Es el número de desviaciones estándar a las que se encuentra un valor dado. Se puede calcular el valor z muestral y poblacional con las ecuaciones (3.7) y (3.8). \\[\\begin{equation} Z = \\frac{X - \\overline{x}}{s} \\tag{3.7} \\end{equation}\\] \\[\\begin{equation} Z = \\frac{X - \\mu}{\\sigma} \\tag{3.8} \\end{equation}\\] Propiedades importantes de los valores Z: No tienen unidades de medida. Si un valor es menor que la media, su valor Z será negativo. 3.3.1.1 Valores Z en R Para el calculo del valor Z de algún número simplemente le extraemos la media \\(\\overline{x}\\) y lo dividimos entre la desviación estándar \\(s\\). Podemos utilizar la función de mutate() del paquete de dplyr para agregar una nueva sección a nuestra base de datos de PlantGrowth. Al utilizar la función group_by() antes de la función mutate() nos aseguramos de que los valores Z se calculen con la media y la desviación estándar de cada tratamiento y no con la media y desviación estándar resultante de todo el conjunto de datos. PlantGrowth &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% mutate(Z = (weight - mean(weight)/sd(weight))) PlantGrowth ## # A tibble: 30 x 3 ## # Groups: group [3] ## weight group Z ## &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 4.17 ctrl -4.46 ## 2 5.58 ctrl -3.05 ## 3 5.18 ctrl -3.45 ## 4 6.11 ctrl -2.52 ## 5 4.5 ctrl -4.13 ## 6 4.61 ctrl -4.02 ## 7 5.17 ctrl -3.46 ## 8 4.53 ctrl -4.10 ## 9 5.33 ctrl -3.30 ## 10 5.14 ctrl -3.49 ## # ... with 20 more rows 3.3.2 Frecuencia absoluta Es el valor total de los datos observados. Por ejemplo, para los tratamientos de la base de datos de PlantGrowth, podemos ver que cada tratamiento tuvo 10 plantas en observación. La frecuencia de cada tratamiento es por ende de 10. Otra situación es el número de veces que cada peso aparece. Por ejemplo, el valor de 4.17 aparece dos veces en los datos, por lo tanto su frecuencia absoluta es de 2. 3.3.2.1 Frecuencia absoluta en R Utilizamos la función table() para su calculo. table(PlantGrowth$group) ## ## ctrl trt1 trt2 ## 10 10 10 Aquí se puede ver que cada tratamiento se realizo con 10 plantas. Ahora si quisieramos ver en los pesos cuántas veces se repite cada valor, lo haríamos por la variable de weight. table(PlantGrowth$weight) ## ## 3.59 3.83 4.17 4.32 4.41 4.5 4.53 4.61 4.69 4.81 4.89 4.92 5.12 5.14 5.17 5.18 ## 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 ## 5.26 5.29 5.33 5.37 5.5 5.54 5.58 5.8 5.87 6.03 6.11 6.15 6.31 ## 1 1 1 1 1 1 1 1 1 1 1 1 1 Y como podemos confirmar, el valor 4.17 es el único que se repite 2 veces. Aparecen los valores de cada uno de nuestros datos y la frecuencia con la que se repiten. En este caso obtuvimos la frecuencia de cada uno de los tratamientos. Como podemos ver, \\(N = 30\\) y cada tratamiento esta compuesto por 10 observaciones. Otra opción es el uso de la función n() junto con group_by(). De hecho, hemos incluido este valor en nuestra tabla de resumen desde un inicio. resumen &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% summarise(CV = sd(weight)/mean(weight)*100, Varianza = sd(weight)^2, SD = sd(weight), Rango = max(weight) - min(weight), Media = mean(weight), Mediana = median(weight), Frec_Absoluta = n()) resumen ## # A tibble: 3 x 8 ## group CV Varianza SD Rango Media Mediana Frec_Absoluta ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 ctrl 11.6 0.340 0.583 1.94 5.03 5.15 10 ## 2 trt1 17.0 0.630 0.794 2.44 4.66 4.55 10 ## 3 trt2 8.01 0.196 0.443 1.39 5.53 5.44 10 3.3.3 Frecuencia relativa Es el valor relativo de cada dato respecto del total como se observa en la ecuación (3.9). Si se le multiplica por 100% se obtiene su valor en porcentaje. \\[\\begin{equation} f_i = \\frac{n_i}{N} \\tag{3.9} \\end{equation}\\] Donde \\(f_i\\) es la frecuencia de la i-ésima observación y \\(n_i\\) es el número de observaciones en la i-ésima observación. 3.3.3.1 Frecuencia relativa en R En este caso utilizamos la función prop.table(). frec &lt;- table(PlantGrowth$group) prop.table(frec) ## ## ctrl trt1 trt2 ## 0.3333333 0.3333333 0.3333333 En este caso obtenemos la frecuencia relativa de cada una de las observaciones de los tratamientos. Como cada una era 10 y \\(N = 30\\) cada una tiene una frecuencia relativa de 0.3333 o 33.33%. Ahora las frecuencias relativas para cada uno de nuestros pesos sería de la siguiente manera. frec2 &lt;- table(PlantGrowth$weight) prop.table(frec2) ## ## 3.59 3.83 4.17 4.32 4.41 4.5 4.53 ## 0.03333333 0.03333333 0.06666667 0.03333333 0.03333333 0.03333333 0.03333333 ## 4.61 4.69 4.81 4.89 4.92 5.12 5.14 ## 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 ## 5.17 5.18 5.26 5.29 5.33 5.37 5.5 ## 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 ## 5.54 5.58 5.8 5.87 6.03 6.11 6.15 ## 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 0.03333333 ## 6.31 ## 0.03333333 Y como podemos ver, la frecuencia del valor 4.17 es el doble que las del resto, lo que quiere decir que este valor se repite 2 veces. De nueva cuenta, otra opción es el uso de la función mutate() para agregar una sección de frecuencia relativa a nuestra tabla con los estadísticos descriptivos pasados. resumen &lt;- resumen %&gt;% mutate(Frec_Relativa = Frec_Absoluta / sum(Frec_Absoluta)) resumen ## # A tibble: 3 x 9 ## group CV Varianza SD Rango Media Mediana Frec_Absoluta Frec_Relativa ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 ctrl 11.6 0.340 0.583 1.94 5.03 5.15 10 0.333 ## 2 trt1 17.0 0.630 0.794 2.44 4.66 4.55 10 0.333 ## 3 trt2 8.01 0.196 0.443 1.39 5.53 5.44 10 0.333 3.3.4 Cuartiles Son medidas que dividen el conjunto de datos en cuatro grupos, con 25% de los valores en cada uno de ellos. Se representan por los símbolos \\(Q_1\\), \\(Q_2\\) y \\(Q_3\\), para el primer, segundo y tercer cuartil. \\(Q_2\\) es equivalente a la mediana. Existen otros estadísticos que pueden ser calculados a partir de los cuartiles como el Rango Intercuartil (\\(RIQ\\)) como se indica en la siguiente fórmula. \\begin{equation} RIQ = Q_3 - Q_1 (\\#eq:RIQ) \\end{equation} 3.3.4.1 Cuartiles en R Para el calculo de los cuartiles en R podemos utilizar la función summary() que viene en los paquetes básicos de R. summary(PlantGrowth) ## weight group Z ## Min. :3.590 ctrl:10 Min. :-7.5661 ## 1st Qu.:4.550 trt1:10 1st Qu.:-6.5986 ## Median :5.155 trt2:10 Median :-3.4749 ## Mean :5.073 Mean :-3.9232 ## 3rd Qu.:5.530 3rd Qu.:-1.7877 ## Max. :6.310 Max. : 0.1573 Como podemos ver, esta función nos da los valores mínimos, máximos, el \\(Q_1\\), \\(Q_3\\), la mediana y la media. Los cinco números utilizados para generar gráfica de caja se encuentran en estos datos. Para sacar estos valores por cada uno de los datos podemos utilizar la función filter() del paquete dplyr. ctrl &lt;- PlantGrowth %&gt;% dplyr::filter(group == &quot;ctrl&quot;) trt1 &lt;- PlantGrowth %&gt;% dplyr::filter(group == &quot;trt1&quot;) trt2 &lt;- PlantGrowth %&gt;% dplyr::filter(group == &quot;trt2&quot;) summary(ctrl) ## weight group Z ## Min. :4.170 ctrl:10 Min. :-4.460 ## 1st Qu.:4.550 trt1: 0 1st Qu.:-4.080 ## Median :5.155 trt2: 0 Median :-3.475 ## Mean :5.032 Mean :-3.598 ## 3rd Qu.:5.293 3rd Qu.:-3.337 ## Max. :6.110 Max. :-2.520 summary(trt1) ## weight group Z ## Min. :3.590 ctrl: 0 Min. :-2.2827 ## 1st Qu.:4.207 trt1:10 1st Qu.:-1.6652 ## Median :4.550 trt2: 0 Median :-1.3227 ## Mean :4.661 Mean :-1.2117 ## 3rd Qu.:4.870 3rd Qu.:-1.0027 ## Max. :6.030 Max. : 0.1573 summary(trt2) ## weight group Z ## Min. :4.920 ctrl: 0 Min. :-7.566 ## 1st Qu.:5.268 trt1: 0 1st Qu.:-7.219 ## Median :5.435 trt2:10 Median :-7.051 ## Mean :5.526 Mean :-6.960 ## 3rd Qu.:5.735 3rd Qu.:-6.751 ## Max. :6.310 Max. :-6.176 3.3.4.2 Valores atípicos Son aquellos valores que se encuentran por encima de \\(Q_3 + 1.5 * RIQ\\) o debajo de \\(Q_1 - 1.5 * RIQ\\). Con estos valores se pueden realizar gráficas de cajas modificadas. Para realizar estas gráficas utilizaremos la paquetería ggplot2 que está incluido en el paquete tidyverse. library(ggplot2) Utilizamos la función ggplot() + geom_boxplot. ggplot(PlantGrowth) + geom_boxplot(aes(group, weight, fill = group)) + xlab(&quot;Grupo&quot;) + ylab(&quot;Peso&quot;) + scale_fill_discrete(name = &quot;Tratamientos&quot;, labels = c(&quot;Control&quot;, &quot;Tratamiento 1&quot;, &quot;Tratamiento 2&quot;)) + theme_classic() Figura 3.1: Gráfica de cajas modificada para la identificación de valores atípicos. Como podemos ver en la gráfica, el tratamiento 1 presenta dos valores atípicos que están por encima del valor \\(Q_3 + 1.5 * IQR\\). 3.4 El uso de la librería dplyr A lo largo de todo esta lección hemos hecho uso de la librería dplyr. Este paquete está incluido dentro de la librería tidyverse. library(tidyverse) La mayoría de estas funciones las hemos estado utilizando a lo largo de esta sección aunque puede que haya algunas que no hayamos aplicado. Las funciones más importantes de este paquete son: group_by: agrupa datos. summarize o summarise: resumen de datos agrupados. filter: encuentra filas con ciertas condiciones. select: junto a starts_with, ends_with o contains mutate: genera nuevas variables. %&gt;%: pipeline. arrange: ordena. Con la función select podemos elegir unas cuantas variables para trabajar. Esto es útil para bases de datos con muchas variables como matrices de abundancias. resumen %&gt;% dplyr::select(group, Media, SD) ## # A tibble: 3 x 3 ## group Media SD ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ctrl 5.03 0.583 ## 2 trt1 4.66 0.794 ## 3 trt2 5.53 0.443 En este caso, solamente nos interesa trabajar con la media y la desviación estándar de nuestros tratamientos. Otra forma de seleccionar las variables es con el argumento starts_with(), por ejemplo, para la selección de los datos del grupo control. PlantGrowth %&gt;% dplyr::select(starts_with(&quot;ctrl&quot;), weight) ## Adding missing grouping variables: `group` ## # A tibble: 30 x 2 ## # Groups: group [3] ## group weight ## &lt;fct&gt; &lt;dbl&gt; ## 1 ctrl 4.17 ## 2 ctrl 5.58 ## 3 ctrl 5.18 ## 4 ctrl 6.11 ## 5 ctrl 4.5 ## 6 ctrl 4.61 ## 7 ctrl 5.17 ## 8 ctrl 4.53 ## 9 ctrl 5.33 ## 10 ctrl 5.14 ## # ... with 20 more rows Como podemos ver, esto despliega los datos de peso seco solamente del grupo de control. También podemos ordenar los datos utilizando la función arrange(). Es importante escribir el argumento .by_group = TRUE para que la función arrange() respete el agrupamiento que hicimos por tratamientos antes del pipeline %&gt;%. PlantGrowth &lt;- PlantGrowth %&gt;% group_by(group) %&gt;% arrange(desc(weight), .by_group = TRUE) "],["probabilidad.html", "Lección 4 Probabilidad 4.1 Probabilidad frecuentista 4.2 Reglas de probabilidad 4.3 Curvas de densidad 4.4 Distribución binomial 4.5 Distribución normal 4.6 Distribución muestral", " Lección 4 Probabilidad La probabilidad es una cantidad numérica que expresa qué tan factible es que ocurra un evento. Normalmente es expresada como P(A), donde A expresa un evento aleatorio. Siempre se encuentra entre un rango de 0 y 1, o expresado en porcentaje, entre 0% y 100%. Existen distintas interpretaciones de la probabilidad como la frecuentista o la bayesiana. En este caso, aprenderemos el enfoque frecuentista como una forma de asignar una probabilidad mensurable a un evento, es decir, la ocurrencia de el evento a la larga. 4.1 Probabilidad frecuentista En este enfoque, la probabilidad de un evento se determina a través por el número de veces que el evento A ocurre en una serie de repeticiones indefinidamente largas. \\[\\begin{equation} P(A) = \\frac{num_{A}}{num_{T}} \\tag{4.1} \\end{equation}\\] Donde \\(num_{A}\\) es el número de veces que se repite el evento A y \\(num_{T}\\) es el número total de repeticiones. 4.2 Reglas de probabilidad Estas son algunas reglas que nos pueden servir para determinar la probabilidad de algunos eventos. La probabilidad de un evento A siempre se encuentra entre 0 y 1. La suma de probabilidades de los eventos tiene que ser igual a 1. La probabilidad de que el evento A no ocurra es \\(1 - P(A)\\) y se denota con el símbolo \\(A_1^C\\), indicando que es el complemento de \\(A_1\\). Si dos eventos \\(A_1\\) y \\(A_2\\) son eventos que no ocurren en conjunto, entonces \\(P(A_1 \\cup A_2) = P(A_1) + P(A_2)\\). Para dos eventos que ocurren en conjunto, \\(P(A_1 \\cup A_2) = P(A_1) + P(A_2) - P(A_1 \\cap A_2)\\). Cabello Café Cabello Negro Cabello Rojo Total Ojos Cafés 400 300 20 720 Ojos Azules 800 200 50 1050 Total 1200 500 70 1770 En este caso, la probabilidad de que alguien tenga el cabello café (CC) o rojo (CR), \\(P(CC \\cup CR) = P(CC) + P(CR) = 500/1770 + 70 / 1770\\). La probabilidad de que alguien tenga el cabello café \\(P(CC) = 1200/1770\\). La probabilidad de tener ojos azules \\(P(OA) = 1050/1770\\). La probabilidad de tener cabello negro y ojos azules \\(P(CN \\cap OA)\\) pueden ocurrir en conjunto ya que hay 200 personas con ojos azules y cabello negro. Entonces \\(P(CN \\cup OA) = P(CN) + P(OA) - P(CN \\cap OA) = 500/1770 + 1050/1770 - 200/1770 = 1350/1770\\). La fórmula de probabilidad condicional es la siguiente: \\[\\begin{equation} P(A_1 | A_2) = \\frac{P(A_1 \\cap A_2)}{P(A_2)} \\tag{4.1} \\end{equation}\\] Si dos eventos, \\(A_1\\) y \\(A_2\\) son independientes, entonces \\(P(A_1 \\cap A_2) = P(A_1)*P(A_2)\\). Para cualquier evento \\(A_1\\) y \\(A_2\\), \\(P(A_1 \\cap A_2) = P(A_1) * P(A_2 | A_1)\\). Por ejemplo, de la tabla anterior, ¿Cuál es la probabilidad de que una persona tenga cabello rojo y ojos cafés? En este caso, \\(P(CR \\cap OA) = P(CR) * P(OA | CR) = 70/1770*20/70 = 20/1770\\). Para dos eventos cualesquiera, \\(A_1\\) y \\(A_2\\), \\(P(A_1) = P(A_2) * P(A_1 | A_2) + P(A_2^C) * P(A_1 | A_2^C )\\) donde \\(A_2^C\\) es el complemento de \\(A_2\\), es decir \\(1 - A_2\\). 4.3 Curvas de densidad Se utilizan para variables continuas. Los histogramas de frecuencias relativas representan las proporciones de las observaciones en cada categoría, en lugar del total de observaciones. Para variables continuas normalmente se utilizan clases muy estrechas para representar al histograma como una curva de densidad. La coordenada y de una curva de densidad representa la escala de densidad y a menudo las frecuencias relativas se representan como áreas debajo de la curva. El área total bajo la curva debe ser igual a 1. Figura 4.1: Curva de densidad. Una probabilidad para una variable continua equivale al área debajo de la curva de densidad entre dos puntos. 4.4 Distribución binomial La distribución binomial de una variable aleatoria es una distribución de probabilidad discreta, que cuenta el número de éxitos tras realizar \\(n\\) veces un experimento, cada intento debe ser independiente entre sí. La probabilidad de éxito es fija entre cada intento y se denota con la letra \\(p\\). Lo primero que se nos viene a la mente con este tipo de distribuciones son lanzamientos de moneda, sin embargo, el comportamiento de muchos genes también sigue una distribución binomial. Normalmente, para que una variable aleatoria sea una variable aleatoria binomial se requieren los siguientes requisitos: Resultados binarios: Solamente existen dos posibilidades para cada intento (éxito o fracaso, cara o cruz, dominante o recesivo, muerto o vivo, niño o niña, etc.). Intentos independientes: Cada prueba o intento deben ser independientes del anterior. El valor de \\(n\\) es fijo: Se sabe con antelación el número de pruebas \\(n\\). Mismo valor \\(p\\): En todos los casos, la probabilidad de éxito o fracaso no debe cambiar, es decir \\(p\\) debe permanecer constante. Resultados mutuamente excluyentes: Es decir, no se puede tener éxito y fracaso al mismo tiempo. Resultados colectivamente exhaustivos: Al menos uno de los dos resultados debe de ocurrir. Ahora bien, la función de masa de probabilidad (PMF) o fórmula de la distribución binomial se indica en la ecuación (4.2). \\[\\begin{equation} P(X = k) = {\\binom{n}{k}}{p^{k}}{q^{n-k}} \\tag{4.2} \\end{equation}\\] Donde: \\(P(X = k)\\) = probabilidad de obtener \\(k\\) éxitos. \\(\\binom{n}{k}\\) = coeficiente binomial, que se calcula con la fórmula (4.3). \\(k\\) = número de éxitos. \\(p\\) = probabilidad de éxito. \\(q\\) = probabilidad de fracaso. \\(n\\) = número de pruebas. \\[\\begin{equation} _{n}C_{k} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!} \\tag{4.3} \\end{equation}\\] 4.4.1 Media y desviación estándar de la distribución binomial Se pueden calcular tanto la media como la desviación estándar de una distribución binomial. La media es el número promedio de éxitos, y la desviación estándar es qué tanto se desvían de la media los valores. La media de una distribución binomial se calcula con la ecuación (4.4). \\[\\begin{equation} \\mu = {n}{p} \\tag{4.4} \\end{equation}\\] En cuanto a la desviación estándar se calcula con la siguiente ecuación (4.5). \\[\\begin{equation} \\sigma = \\sqrt{{n}{p}{(1-p)}} = \\sqrt{{n}{p}{q}} \\tag{4.5} \\end{equation}\\] En caso de querer obtener la varianza, simplemente tomamos la ecuación (4.5) sin aplicar la raíz cuadrada. \\[\\begin{equation} \\sigma^2 = {n}{p}{(1-p)} = {n}{p}{q} \\tag{4.6} \\end{equation}\\] 4.4.2 Distribución binomial en R Para utilizar la distribución binomial en R es bastante sencillo. Veamos el siguiente ejemplo. Ejemplo: Supongamos que analizamos a 5 individuos de una población en la que el 37% de las personas presentan un alelo mutante. Las probabilidades de las distintas configuraciones están dadas por la distribución binomial, en donde \\(n\\) = 5 y \\(p\\) = 0.37. ¿Cuál es la probabilidad de que exactamente 2 personas sean mutantes? Antes de continuar, hay que saber que existen 4 distintos comandos de la función binomial: -dbinom() nos da un valor exacto de la distribución binomial en el punto indicado. -pbinom() nos da la probabilidad acumulada de un evento. -qbinom() toma el valor de probabilidad que le ponemos como primer argumento y nos da como regreso un número cuya probabilidad acumulada empate con el valor de la probabilidad. -rbinom() genera cierta cantidad de número aleatorios de acuerdo con la probabilidad y el número de pruebas realizadas. En este caso, queremos conocer la probabilidad exacta de que 2 personas sean mutantes. Para esto necesitamos la función dbinom(x, size, prob), donde el argumento x equivale al número de éxitos, size al número de ensayos y prob a la probabilidad de éxito. dbinom(2, 5, 0.37) ## [1] 0.3423143 Ejemplo: En Estados Unidos, 85% de la población tiene sangre Rh positivo. Supongamos que tomamos 6 personas y contamos cuántos tiene Rh positivo. En este caso \\(Y\\) representará cuántas personas tienen Rh positivo dentro del grupo de 6. ¿Cuál es la probabilidad de \\(Y\\) = 4? ¿Y la probabilidad de que al menos 4 personas sean Rh positivo? ¿Y la probabilidad de que haya al menos 1 persona con Rh negativo? En este caso debemos utilizar dos comandos, dbinom() y pbinom(), con uno calcularemos \\(Y = 4\\) y con el otro \\(Y \\ge 4\\) (4 o más). Como queremos obtener \\(P(Y \\ge 4)\\), entonces \\(P(Y \\ge 4) = P(Y = 4) + P(Y=5) + P(Y=6)\\), utilizamos el argumento lower.tail y lo ponemos en FALSE para indicar que vamos a trabajar con un valor mínimo de 4, para arriba. Para el caso de al menos una persona con Rh negativo \\(P(Y &lt; 6)\\), tenemos dos opciones. Usar dbinom() cinco veces para calcular el valor individual de \\(P(Y = 0) + P(Y = 1) + P(Y = 2) \\cdots + P(Y = 5)\\), o calcular \\(P(Y = 6)\\) y restarle a 1 este valor. Como vemos ambas operaciones dan los mismos resultados, pero es más sencilla la segunda. #Probabilidad de que 4 personas tengan Rh positivo. dbinom(4, 6, 0.85) ## [1] 0.1761771 #Probabilidad de que al menos 4 personas (pueden ser 4, 5 o 6) tengan Rh positivo. pbinom(3, 6, 0.85, lower.tail = FALSE) ## [1] 0.9526614 #Probabilidad de que al menos 1 persona tenga Rh positivo. dbinom(0, 6, 0.85) + dbinom(1, 6, 0.85) + dbinom(2, 6, 0.85) + dbinom(3, 6, 0.85) + dbinom(4, 6, 0.85) + dbinom(5, 6, 0.85) ## [1] 0.6228505 1 - dbinom(6, 6, 0.85) ## [1] 0.6228505 4.5 Distribución normal Una distribución normal corresponde a una curva en forma de campana, con ciertas características específicas. Se utiliza para representar la distribución de los valores de una variable \\(X\\), de dos maneras distintas: (1) como una aproximación a un histograma basado en los valores muestreados de la variable \\(X\\) o; (2) como una representación idealizada de la distribución poblacional de \\(X\\). Las curvas con distribución normal toman su forma por dos elementos muy importantes: la media \\(\\mu\\) y su desviación estándar \\(\\sigma\\). Cuando se tiene una curva con distribución normal, se expresa de la siguiente manera \\(X \\sim N(\\mu, \\sigma)\\). La fórmula de la distribución normal se encuentra en la ecuación (4.7). No se trata de cualquier curva simétrica, si no de una curva simétrica específica. \\[\\begin{equation} f(x) = \\frac{1}{{\\sigma}{\\sqrt{2 \\pi}}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2} \\tag{4.7} \\end{equation}\\] La función \\(f(x)\\) se conoce como función de densidad de probabilidad (PDF) y expresa la altura de la curva como una función de la posición en el eje horizontal. El centro de una curva normal es \\(x = \\mu\\), los puntos de inflexión están en \\(x = \\mu + \\sigma\\) y \\(x = \\mu - \\sigma\\). En principio la curva se extiende hasta el infinito, pero tres desviaciones estándar de la media hacia el valor negativo o positivo da como resultado valores demasiado pequeños. El ancho y alto de una curva normal están determinados por la desviación estándar \\(\\sigma\\). Figura 4.2: Forma de la distribución normal. Normalmente lo que nos interesa de una curva con distribución normal es el área debajo de la curva. Para esto utilizamos la escala estandarizada, en el cual el valor del eje horizontal se denomina valor Z. La escala de Z mide las desviaciones estándar a partir de la media, por ejemplo, \\(z = 1\\) corresponde a una desviación estándar de la media. Para transformar nuestros datos a la escala Z simplemente aplicamos la ecuación (4.8) y a la variable Z se le conoce como una variable de distribución normal estándar, ya que se encuentra estandarizada y no importa en que valor se encuentren los datos originales (kg, °C, cm, mmHg, etc.), la variable Z es adimensional. \\[\\begin{equation} Z = \\frac{X - \\mu}{\\sigma} \\tag{4.8} \\end{equation}\\] Una vez que nuestras variables se encuentran estandarizadas en el valor Z, podemos utilizar tablas de Z para realizar el cálculo debajo del área que corresponde al valor Z obtenido, aunque claro, también podemos hacer estos cálculos en R. Hay que tener en cuenta que para una curva de distribución normal estándar: 68% del área se encuentra entre \\(\\pm\\) 1 distribución estándar. 95% del área se encuentra entre \\(\\pm\\) 2 distribuciones estándar. 99.7% del área se encuentra entre \\(\\pm\\) 3 distribuciones estándar. 4.5.1 Distribución normal en R De manera similar a la distribución binomial, en R encontramos comandos similares para la distribución normal, donde tenemos: -dnorm() nos da un valor de densidad normal en determinado punto (valor puntual de la función de densidad). -pnorm() nos da un valor de densidad normal acumulado hasta cierto punto (área debajo de la curva). -qnorm() toma el valor de densidad normal que le ponemos como primer argumento y nos da como regreso un número cuya densidad normal acumulada empate con el valor de densidad normal ingresado. -rnorm() genera cierta cantidad de número aleatorios de acuerdo al valor de densidad normal. Intentemos resolver algunos ejercicios. Ejemplo: En una población de peces de la especie Pomolobus aestivalis, la longitud de los individuos sigue una distribución normal. La media de la longitud es de 54.0 mm, y la desviación estándar es de 4.5 mm2. ¿Qué porcentaje de los peces mide menos de 60 mm? ¿Qué porcentaje de los peces mide más de 51 mm? ¿Qué porcentaje de los peces miden entre 51 mm y 60 mm? Para responder la primer pregunta, debemos transformar nuestros datos a valores Z, ya que se encuentran en mm. Para esto aplicamos la ecuación (4.8). En R es una operación relativamente sencilla de hacer. (60 - 54)/(4.5) ## [1] 1.333333 Como podemos ver, el valor Z de 60 mm es igual a 1.33. Lo siguiente sería encontrar el área bajo la curva que corresponda a este valor Z. Para esto utilizamos la función pnorm(). pnorm(1.33, 0, 1, lower.tail = TRUE) ## [1] 0.9082409 Figura 4.3: Curva de distribución normal con el área sombreada correspondiente a un valor Z = 1.33 De nuevo, el argumento lower.tail = TRUE significa que encontrará la probabilidad acumulada de valores Z menores a 1.33 hasta 1.33. Como podemos ver la probabilidad de que un pez mida menos de 60 mm es de 90.82%. Para la segunda pregunta, primero debemos encontrar el valor de Z correspondiente a 51 mm y después basta con cambiar el argumento lower.tail a FALSE. (51 - 54)/(4.5) ## [1] -0.6666667 pnorm(-0.67, 0, 1, lower.tail = FALSE) ## [1] 0.7485711 Como podemos ver el resultado indica que 75.86% de los peces miden más de 51 mm. Bastante sencillo, ¿no? Figura 4.4: Curva de distribución normal con el área sombreada correspondiente a un valor Z = -0.67, pero partiendo desde el lado positivo de la curva. Ahora para la última pregunta, simplemente calculamos la probabilidad acumulada hasta nuestro valor Z más grande, que en este caso corresponde a 1.33 y le restamos la probabilidad acumulada del valor Z más pequeño, que corresponde -0.67. pnorm(1.33, 0, 1) - pnorm(-0.67, 0, 1) ## [1] 0.656812 Como resultado obtenemos que el 65.68% de los peces se encuentran en longitudes de entre 51 mm y 60 mm. Si nos damos cuenta, la distribución normal puede, de cierta manera, interpretarse como una distribución de probabilidad continua. Figura 4.5: Curva de distribución normal con el área sombreada correspondiente a un intervalo entre Z = -0.67 y Z = 1.33. En algunas ocasiones, queremos encontrar el valor Z correspondiente a un área bajo la curva determinada, para este tipo de ocasiones, utilizamos la función qnorm(). Del ejemplo anterior, supongamos que queremos encontrar el percentil 70 de la distribución de la longitud de los peces. Supongamos que este valor está representado por la variable \\(y\\). En otras palabras, queremos encontrar el valor tal que el 70% de las longitudes de los peces son menores que \\(y\\) y el 30% son mayores. qnorm(0.7, 0, 1) ## [1] 0.5244005 Como podemos ver, el valor Z correspondiente es 0.5244. Ahora, utilizando la ecuación (4.8) podemos realizar un despeje muy sencillo y obtener la fórmula \\(y = Z* \\sigma + \\mu = 0.5244 * 4.5 + 54 = 56.3\\). Esto quiere decir que 56.3 mm es el percentil 70 de la distribución de nuestros datos. Figura 4.6: Curva de distribución normal con el área sombreada correspondiente a un valor Z = -0.67, pero partiendo desde el lado positivo de la curva. 4.5.2 Pruebas de normalidad en R Ya que muchos procedimientos estadísticos se basan en datos provenientes de una población con distribución normal, es importante saber si nuestros datos siguen está distribución. Uno de los métodos más utilizados son los gráficos cuantil-cuantil, gráficos Q-Q o Q-Q plot. Veamos un ejemplo con datos de plantas que vienen incluidas en ggplot2. data(&quot;PlantGrowth&quot;) PlantGrowth ## weight group ## 1 4.17 ctrl ## 2 5.58 ctrl ## 3 5.18 ctrl ## 4 6.11 ctrl ## 5 4.50 ctrl ## 6 4.61 ctrl ## 7 5.17 ctrl ## 8 4.53 ctrl ## 9 5.33 ctrl ## 10 5.14 ctrl ## 11 4.81 trt1 ## 12 4.17 trt1 ## 13 4.41 trt1 ## 14 3.59 trt1 ## 15 5.87 trt1 ## 16 3.83 trt1 ## 17 6.03 trt1 ## 18 4.89 trt1 ## 19 4.32 trt1 ## 20 4.69 trt1 ## 21 6.31 trt2 ## 22 5.12 trt2 ## 23 5.54 trt2 ## 24 5.50 trt2 ## 25 5.37 trt2 ## 26 5.29 trt2 ## 27 4.92 trt2 ## 28 6.15 trt2 ## 29 5.80 trt2 ## 30 5.26 trt2 Como podemos ver, tenemos tres grupos, el control, tratamiento 1 y tratamiento 2. Vamos a enfocarnos solamente en los datos del grupo del tratamiento 1. Datos &lt;- PlantGrowth %&gt;% dplyr::select(starts_with(&quot;trt1&quot;), weight) Datos ## weight ## 1 4.17 ## 2 5.58 ## 3 5.18 ## 4 6.11 ## 5 4.50 ## 6 4.61 ## 7 5.17 ## 8 4.53 ## 9 5.33 ## 10 5.14 ## 11 4.81 ## 12 4.17 ## 13 4.41 ## 14 3.59 ## 15 5.87 ## 16 3.83 ## 17 6.03 ## 18 4.89 ## 19 4.32 ## 20 4.69 ## 21 6.31 ## 22 5.12 ## 23 5.54 ## 24 5.50 ## 25 5.37 ## 26 5.29 ## 27 4.92 ## 28 6.15 ## 29 5.80 ## 30 5.26 Recordemos que podemos utilizar la librería dplyr para extraer ciertos datos de nuestras matrices de datos. Lo que haremos ahora es utilizar el gráfico Q-Q para comprar los datos de nuestra muestra con unos datos teóricos que siguen una distribución normal. En caso de que nuestros datos se comporten de manera normal, deberíamos de tener casi una línea recta. Para esto necesitaremos la librería ggpubr. library(ggpubr) ggqqplot(Datos$weight) + xlab(&quot;Teórico&quot;) + ylab(&quot;Muestra&quot;) Figura 4.7: Gráfico Q-Q comparando una muestra de datos contra una muestra teórica con distribución normal. Otra opción sería realizar el gráfico de densidad, pero muchas veces es difícil identificar la forma de campana en cierto conjunto de datos, así que los gráficos Q-Q son de gran ayuda. Otra opción para realizar una prueba de normalidad conocida como prueba de Shapiro-Wilks (aunque no se recomienda que para \\(n &gt; 50\\)), pero es muy sensible a ligeras desviaciones de la normalidad, sobre todo con un tamaño de muestra grande. Es muy sencillo de realizar en R, simplemente utilizamos el comando shapiro_test() del paquete rstatix. En este caso, vamos a analizar si nuestros dos tratamientos y el control siguen una distribución normal. Para esto, vamos a hacer uso de la librería dplyr. library(rstatix) ## ## Attaching package: &#39;rstatix&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## filter PlantGrowth %&gt;% group_by(group) %&gt;% shapiro_test(weight) #Agrupamos los datos por tipo de tratamiento y hacemos la prueba a la variable &quot;weight&quot;. ## # A tibble: 3 x 4 ## group variable statistic p ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ctrl weight 0.957 0.747 ## 2 trt1 weight 0.930 0.452 ## 3 trt2 weight 0.941 0.564 ¿Cómo interpretamos los resultados y qué significa el valor-p? Bueno, ya que el control y los dos tratamientos tienen un valor-p &gt; 0.05 decimos que se distribuyen de manera normal. Valores-p menores a 0.05 son indicativos fuertes de no-normalidad. Después de obtener un valor menor a 0.05, podríamos corroborar esto con un gráfico Q-Q o con un histograma para ver la forma de la distribución de nuestros datos. 4.6 Distribución muestral La variabilidad entre muestras aleatorias que provienen de una misma población se conoce como variabilidad de muestreo. Una distribución de probabilidad que caracteriza algún aspecto de la variabilidad de muestreo se conoce como distribución muestral. Usualmente los valores de una muestra se parecen a los de la población de la cuál provienen. Una distribución muestral nos indica qué tan cerca la resemblanza entre entre la muestra y la población es probable que sea. Normalmente tomamos solamente una muestra aleatoria de una población. Pero para visualizar la distribución muestral, necesitamos realizar un meta-estudio, que consiste en repetir de manera indefinida, réplicas del mismo estudio. Por ejemplo, si un estudio consiste en extraer una muestra aleatoria de tamaño \\(n\\) de una población, un meta-estudio consiste en repetir varias veces la extracción de una muestra de tamaño \\(n\\) de una población. Por lo tanto, las probabilidades relativas de una muestra aleatoria se pueden interpretar como frecuencias relativas en un meta-estudio. Conocer la distribución muestral nos permite hacer afirmaciones de probabilidad de otras posibles muestras. Una pregunta natural a realizar es, ¿Qué tan parecida es la media de la muestra \\(\\overline{x}\\) de la media de la población \\(\\mu\\)? Aunque con una sola muestra no podemos responder esta pregunta, si pensamos en un modelo de muestreo aleatorio y tomamos la media muestral como una variable \\(\\overline{X}\\), podemos hacer ciertas inferencias. Reformulamos nuestra pregunta a ¿Qué tan cerca de \\(\\mu\\) es probable que este \\(\\overline{X}\\)? Nuestra respuesta la encontramos en la distribución muestral de \\(\\overline{X}\\). Tenemos que tener en cuenta que, en promedio, la media de la distribución muestral \\(\\overline{X}\\) equivale a la media de la población \\(\\mu\\). Esto se ve mejor en la fórmula (4.9). \\[\\begin{equation} \\mu_{\\overline{X}} = \\mu \\tag{4.9} \\end{equation}\\] La fórmula de la desviación estándar de la muestra es un poco menos intuitiva, aunque si se analiza de manera detallada tiene sentido. \\[\\begin{equation} \\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}} \\tag{4.10} \\end{equation}\\] Mientras el tamaño de muestra incrementa, la desviación estándar de \\(\\overline{X}\\) disminuye. Es decir para muestras más grandes existe menos variación. La forma está determinada por el tamaño de muestra y la naturaleza de la población. Si la población \\(X\\) se distribuye de manera normal, entonces la distribución muestral de \\(\\overline{X}\\) será también normal, sin importar el tamaño de nuestra \\(n\\). Además el teorema del límite central indica que si obtenemos una \\(n\\) suficientemente grande, la distribución muestral de \\(\\overline{X}\\) será aproximadamente normal incluso para muestras cuya población \\(X\\) no se distribuye de manera normal. Ejemplo: Supongamos que tenemos una población del Carbonerito Mexicano (Poecile sclateri) en la cuál el peso medio es de \\(\\mu = 11 g\\) y la desviación estándar \\(\\sigma = 1.2 g\\). Supongamos que tomamos una muestra aleatoria de seis aves. Dejemos que \\(\\overline{x}\\) represente la media del peso de las seis aves. Ya que sabemos que el peso de esta ave sigue una distribución normal en la población, también nuestras muestras seguirán una distribución normal. Para este caso, la media y la desviación estándar de nuestra muestra serán las siguientes: \\[\\begin{equation} \\mu_{\\overline{X}} = \\mu = 11 g\\\\ \\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{1.2}{\\sqrt{6}} = 0.49 g \\end{equation}\\] En este caso \\(\\mu_{\\overline{X}} = 11 g\\) y \\(\\sigma_{\\overline{X}} = 0.49 g\\). De tal manera que, en promedio la media de la muestra será 11 g, sin embargo, el 68% de las veces \\(\\overline{X}\\) se encontrará entre \\(11g \\pm 0.49g\\) y el 95% de las veces se encontrará entre \\(11g \\pm 0.98g\\). Figura 4.8: Distribución muestral proveniente de una población de Sclateri poecile. Esta distribución muestral expresa distintas posibilidades para los valores de \\(\\overline{X}\\). Supongamos que quisiéramos saber la probabilidad de que la media de una muestra de seis aves sea mayor a 11.5 g. Ya que nuestros datos son normales, podemos usar la transformación a valores Z para obtener nuestro resultado. \\[\\begin{equation} Z = \\frac{\\overline{x}-\\mu_\\overline{X}}{\\sigma_{\\overline{X}}} = \\frac{11.5 - 11}{0.49} = 1.0204 \\end{equation}\\] Ya que nuestro valor Z = 1.0204, usamos la función pnorm() para encontrar nuestra área bajo la curva. pnorm(1.0204, mean = 0, sd = 1, lower.tail = FALSE) ## [1] 0.1537694 De hecho, ni siquiera es necesario realizar la transformación a valores Z en R ya que podemos modificar los parámetros de la función pnorm(). pnorm(11.5, mean = 11, sd = 0.49, lower.tail = FALSE) ## [1] 0.1537675 Debido a que hemos redondeado la desviación estándar el valor es ligeramente distinto, pero en esencia el resultado es el mismo. Entonces podemos concluir que \\[\\begin{equation} P(\\overline{X} &gt; 11.5) = P(Z &gt; 1.0204) = 0.1538 \\approx 0.15 \\end{equation}\\] Figura 4.9: Probabilidad de que la media de una muestra de seis aves de la especie Poecile sclateri sea mayor a 11.5. Si eligiéramos muchas muestras aleatorias provenientes de esta población cerca del 15% de las muestras tendrían una media mayor a 11.5 g. El tamaño de la muestra tiene un efecto directo sobre la forma de nuestra curva. Básicamente, muestras más grandes dan un \\(\\sigma_\\overline{X}\\) menor, y por ende dan un menor error de muestreo. En seguida se muestran distintas gráficas con distintas \\(\\mu_\\overline{X}\\). Para este caso hipotético, \\(\\mu = 100, \\sigma = 40\\). Figura 4.10: Cambios en la forma de la curva dependientes de la desviación estándar muestral. Figura 4.11: Cambios en la forma de la curva dependientes de la desviación estándar muestral. Qué tan cerca esta \\(\\overline{X}\\) de \\(\\mu\\) depende del tamaño de la muestra \\(n\\). La media de una muestra grande no necesariamente está más cerca a la media poblacional que la media de una muestra pequeña, pero existe mayor probabilidad de que lo este. 4.6.1 Poblaciones, muestras y distribuciones muestrales Una vez llegado a este punto puede que exista confusión entre los valores de una población, de una muestra y de una distribución muestral. Para esto aclaremos los siguientes puntos, en torno a una variable \\(X\\). En una población, los estadísticos descriptivos como la media y la desviación estándar se representan por los siguientes símbolos: \\(\\mu\\): media poblacional. \\(\\sigma\\): desviación estándar poblacional. En una muestra, los mismos estadísticos se representan por los siguientes símbolos: \\(\\overline{x}\\): media muestral. \\(s\\): desviación estándar poblacional. En una distribución muestral lo que nosotros hacemos es repetir un muestreo indefinidas veces (meta-estudio) y de cada muestreo extraer la media muestral \\(\\overline{x}\\). Lo que representa la distribución muestral es una distribución de medias, en lugar de observaciones individuales. \\(\\mu_\\overline{X}\\): media de una distribución muestral. \\(\\sigma_\\overline{X}\\): desviación estándar de una distribución muestral. "],["inferencia-de-las-medias.html", "Lección 5 Inferencia de las medias 5.1 Error estándar de la media 5.2 Intervalo de confianza para \\(\\mu\\)", " Lección 5 Inferencia de las medias En esta lección aprenderemos a hacer inferencias, basadas en un modelo de muestreo aleatorio. Usaremos información proveniente de nuestras muestras aleatorias para inferir hechos acerca de la población de la que fueron tomadas. Utilizamos datos para determinar alguna característica de la población original o para medir la precisión de nuestras estimaciones. Sabemos que al tomar muestras de una población, nuestros datos son susceptibles a un error de muestreo. Cabe aclarar que este error no solamente tiene que ver con la precisión de medición, si no que este error surge por el hecho de que no estamos tomando en cuenta los datos de toda la población. 5.1 Error estándar de la media El error estándar mide la magnitud del error de muestreo, es decir, la discrepancia entre \\(\\overline{x}\\) y \\(\\mu\\) utilizando la distribución muestral de \\(\\overline{X}\\). La fórmula del error estándar es la siguiente: \\[\\begin{equation} SE_\\overline{X} = \\frac{s}{\\sqrt{n}} \\tag{5.1} \\end{equation}\\] Como podemos ver, esta fórmula es bastante similar a la fórmula de la desviación estándar de la muestra \\(\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}\\). Normalmente, la diferencia entre \\(\\mu\\) y \\(\\overline{x}\\) es unos cuantos errores estándar. De hecho, encontramos a \\(\\overline{x}\\) a un error estándar de \\(\\mu\\) bastante seguido. Hay que destacar que el error estándar dependen de la desviación estándar muestral \\(s\\) y del tamaño de muestra \\(n\\). Es importante destacar la diferencia entre el error estándar y la desviación estándar. La desviación estándar describe la dispersión de los datos de una muestra, mientras que el error estándar describe la falta de fidelidad en la media de una muestra como estimación de la media poblacional, debido al error de muestreo. Una forma de disminuir el error estándar es incrementando el tamaño de muestra \\(n\\). En las gráficas podemos ver el error estándar o la desviación estándar representadas como intervalos en nuestros puntos. Por ejemplo, las siguientes gráficas representan la desviación estándar en la figura 5.1 y el error estándar en la figura 5.2. Como podemos ver, la dispersión de los datos es mayor al error estándar. Figura 5.1: Gráfico con la desviación estándar representada en forma de intervalo. Figura 5.2: Gráfico con el error estándar representado en forma de intervalo. 5.2 Intervalo de confianza para \\(\\mu\\) Un intervalo de confianza nos sirve para determinar qué tan cerca está de \\(\\mu\\) nuestra media muestral \\(\\overline{x}\\). Ya que no podemos medir de manera directa \\(\\mu\\), utilizamos \\(\\overline{x}\\) adicional al error estándar \\(SE_\\overline{X}\\) como se indica en la fórmula (5.2). \\[\\begin{equation} \\overline{x} \\pm {2}*{SE_\\overline{X}} \\tag{5.2} \\end{equation}\\] ¿Por qué utilizar dos veces \\(SE_\\overline{X}\\)? Porque al utilizarlo sabemos que el 95% de las veces \\(\\mu\\) se encontrará en este intervalo. Si utilizáramos solamente un \\(SE_\\overline{X}\\) solamente estaríamos seguros de que \\(\\mu\\) se encuentra en este intervalo el 68% de las veces. Esta idea está basada en la distribución muestral de \\(X\\) que vimos en la lección anterior. Al estandarizar nuestra variable \\(X\\) y transformarla en valores \\(Z\\), lo que buscamos es un área de 0.95. Estos valores Z corresponden a -1.96 como límite inferior y 1.96 como limite superior. \\[\\begin{equation} P({-1.96}&lt;{Z}&lt;1.96) = 0.95 \\\\ P({-1.96}&lt;{\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}}&lt;1.96) = 0.95 \\\\ P({-1.96\\times{\\sigma/\\sqrt{n}}}&lt;{{\\overline{X}-\\mu}}&lt;1.96\\times{\\sigma/\\sqrt{n}}) = 0.95 \\\\ P({-\\overline{X}-1.96\\times{\\sigma/\\sqrt{n}}}&lt;{-\\mu}&lt;-\\overline{X}1.96\\times{\\sigma/\\sqrt{n}}) = 0.95 \\\\ P({\\overline{X}-1.96\\times{\\sigma/\\sqrt{n}}}&lt;{\\mu}&lt;\\overline{X}1.96\\times{\\sigma/\\sqrt{n}}) = 0.95 \\\\ \\end{equation}\\] A partir de este despeje obtenemos la fórmula para un intervalo de confianza que contendrá a \\(\\mu\\) el 95% de las veces. \\[\\begin{equation} \\overline{X} \\pm 1.96\\frac{\\sigma}{\\sqrt{n}} \\tag{5.3} \\end{equation}\\] Si en este caso, cambiamos \\(\\sigma\\) por \\(s\\), podemos calcular el intervalo de confianza para nuestra muestra. William Sealy Gosset, quién publicó sus hallazgos bajo el seudónimo de Student, descubrió un método para preservar la interpretación del 95% y desde entonces este método lleva su seudónimo. Básicamente, si la muestra proviene de una población normal, y si remplazamos \\(\\sigma\\) del intervalo por \\(s\\), la interpretación del 95% se puede preservar utilizando la nueva cantidad denotada como \\(t_{0.025}\\) y que está relacionada con una distribución conocida como distribución \\(t\\) de Student. 5.2.1 Distribución \\(t\\) de Student La distribución \\(t\\) de Student es una distribución teórica continua, usada para distintos própositos en estadística, por ejemplo, para la construcción de intervalos de confianza. La distribución depende de una cantidad conocida como grados de libertad o df. La forma de una distribución \\(t\\) de Student es de campana, similar a la distribución normal, pero con una desviación estándar mayor. Conforme los grados de libertad aumentan, la curva de una distribución \\(t\\) de Student se asemeja más a una curva normal (podría decirse que una curva normal es una curva \\(t\\) de Student con \\(df = \\infty\\)). En la figura 5.3 podemos ver como la forma de una distribución \\(t\\) de Student cambia conforme los \\(df\\) aumentan. La línea punteada es una curva con distribución normal. Figura 5.3: Curvas con distribución t de Student y cómo cambian dependiendo de los df. La cantidad \\(t_{0.025}\\) se conoce como valor crítico al 5% de dos colas de una distribución \\(t\\) de Student. El área entre \\(-t_{0.025}\\) y \\(t_{0.025}\\) contiene el 95% del área de la curva. Es decir el área debajo de \\(-t_{0.025}\\) y encima de \\(t_{0.025}\\) suman en total 5% como se ve en la figura 5.4. Figura 5.4: Valores críticos de una distribución t de Student Existen tablas de distribución \\(t\\) de Student que se utilizan para encontrar los valores críticos acorde con nuestros grados de libertad. Al igual que la distribución binomial y normal, R viene con funciones para la distribución \\(t\\) de Student. Estos son los siguientes: -dt() nos da un valor de densidad en determinado punto de la distribución de \\(t\\) (valor puntual de la función de densidad). -pt() nos da un valor de densidad acumulado hasta cierto punto en la distribución de \\(t\\) (área debajo de la curva). -qt() toma el valor de densidad que le ponemos como primer argumento y nos da como regreso un número cuya densidad acumulada empate con el valor de densidad ingresado. -rt() genera cierta cantidad de número aleatorios de acuerdo al valor de densidad. Sin embargo en este caso, en lugar de contar con el argumento n para el tamaño de muestra, contamos con otro argumento df para los grados de libertad. 5.2.2 Construcción de un intervalo de confianza para \\(\\mu\\) El primer paso para construir nuestro intervalo de confianza es elegir nuestro nivel de confianza (generalmente es 95% pero esto no quiere decir que siempre tenga que ser así). Si quisiéramos un nivel de confianza de 90% utilizamos un valor crítico de \\(t_{0.05}\\). Después tenemos que establecer los límites de nuestro intervalo utilizando la siguiente fórmula (para intervalos con 95% de confianza): \\[\\begin{equation} \\overline{x} \\pm t_{0.025}\\frac{s}{\\sqrt{n}} \\tag{5.4} \\end{equation}\\] Como vimos, el valor crítico de \\(t\\) es determinado por los grados de libertad. Estos se calculan utilizando las siguiente fórmula: \\[\\begin{equation} df = n - 1 \\tag{5.5} \\end{equation}\\] ¿Por qué se calculan así los grados de libertad? Bueno, las desviaciones (\\(x_i - \\overline{x}\\)) deben de sumar 0 en total, por lo que solamente una (\\(n - 1\\)) de estas desviaciones puede variar libremente. Ejemplo: Una muestra del área de las alas obtenida de una población de la Mariposa Monarca (Danaus plexippus) de 14 ejemplares tiene una media \\(\\overline{x} = 32.8143cm^2\\) y una desviación estándar \\(s = 2.4757 cm^2\\). Sabemos que los datos provienen de una población con distribución normal. ¿Cuál sería el intervalo de confianza al 95% para esta muestra? El primer paso es calcular los grados de libertad. \\[\\begin{equation} df = n - 1 = 14 - 1 = 13 \\end{equation}\\] Como queremos un intervalo de confianza al 95%, utilizamos el valor crítico de \\(t_{0.025}\\). Para encontrar este valor podemos buscarlo en una tabla de \\(t\\) o utilizar las funciones de R. qt(0.025, 13, lower.tail = FALSE) ## [1] 2.160369 Por lo tanto el intervalo de confianza al 95% para nuestra muestra es \\[\\begin{equation} 32.8143 \\pm {2.16}{\\frac{2.4757}{\\sqrt{14}}} \\\\ 32.8143 \\pm {2.16}{0.6617} \\\\ 32.8143 \\pm 1.4293 \\end{equation}\\] De nuevo, esto se puede calcular en R de manera sencilla. 32.8143 + 2.160*(2.4757/sqrt(14)) ## [1] 34.24348 32.8143 - 2.160*(2.4757/sqrt(14)) ## [1] 31.38512 Una forma compacta de escribir el intervalo de confianza es con el límite inferior y superior separados por una coma y entre parentésis (\\(31.4, 34.2\\)). Con esta información sabemos entonces que \\(31.4cm^2 &gt; \\mu &gt; 34.2cm^2\\), nuestra media poblacional \\(\\mu\\) se encuentra, el 95% de las veces, en este intervalo.| "],["references.html", "References", " References "],["análisis-de-varianza-anova.html", "Lección 6 Análisis de Varianza (ANOVA) 6.1 Prueba de normalidad 6.2 Prueba de homocedasticidad 6.3 Análisis de varianza (ANOVA de una vía) 6.4 Pruebas post hoc", " Lección 6 Análisis de Varianza (ANOVA) Para realizar un análisis de varianza o ANOVA es necesario cumplir con ciertos supuestos. Estos supuestos son similares para otro tipo de pruebas y se encuentran descritas en la sigueinte lista: Distribución normal de los datos. Homocedasticidad (varianzas iguales). Datos independientes. La distribución normal y la homocedasticidad son hasta cierto punto flexibles. Sin embargo, el ANOVA es sumamente sentitivo a muestras no independientes. Pese a su nombre, el análisis de varianza en realidad busca diferencias en las medias (\\(\\mu\\)) de las muestras. Antes de hacer el ANOVa debemos buscar una manera de comprobar la distribución normal y la homocedasticidad de los datos. Esto es relativamente sencillo de hacer. 6.1 Prueba de normalidad Una de las pruebas de normalidad más utilizadas es la prueba de Shapiro-Wilk. El resultado de la prueba de Shapiro-Wilk es un valor-p que se puede interpretar de la siguiente manera: Valor-p \\(&lt;\\) 0.01: No normalidad. Valor-p \\(&lt;\\) 0.05: No normalidad. Valor-p \\(\\ge\\) 0.05: Sin evidencia concluyente de no normalidad. Usualmente un valor-p \\(&lt;\\) 0.05 es suficiente para indicar que nuestros datos no se distribuyen de manera normal. Esta base de datos incluye 2 variables, los valores del peso y el tratamiento que recibieron las plantas. Para esta ocasión vamos a trabajar con la base de datos PlantGrowth que viene incluida en R. data(&quot;PlantGrowth&quot;) Vamos a realizar una gráfica de nuestros datos para darnos una idea de su comportamiento. library(ggplot2) ggplot(PlantGrowth) + geom_point(aes(group, weight, color = group)) + xlab(&quot;Grupo&quot;) + ylab(&quot;Peso&quot;) + scale_color_discrete(name = &quot;Tratamientos&quot;, labels = c(&quot;Control&quot;, &quot;Tratamiento 1&quot;, &quot;Tratamiento 2&quot;)) + theme_classic() Figura 6.1: Gráfica con los distintos tratamientos. Otra forma de visualizar los datos es con un boxplot que puede ir dándonos idea más o menos de cómo se distribuyen nuestros datos. library(ggplot2) ggplot(PlantGrowth) + geom_boxplot(aes(group, weight, fill = group)) + xlab(&quot;Grupo&quot;) + ylab(&quot;Peso&quot;) + scale_fill_discrete(name = &quot;Tratamientos&quot;, labels = c(&quot;Control&quot;, &quot;Tratamiento 1&quot;, &quot;Tratamiento 2&quot;)) + theme_classic() Figura 6.2: Graficos de boxplot para visualización de las distribuciones de los datos. Computar la prueba de normalidad de Shapiro-Wilk sumamente sencillo y se hace con la función shapiro_test() de la librería rstatix. Para esto primero tenemos que agrupar nuestros datos por tratamientos con la función group_by() del paquete de dplyr. library(tidyverse) library(rstatix) PlantGrowth %&gt;% group_by(group) %&gt;% shapiro_test(weight) #Agrupamos los datos por tratamiento. ## # A tibble: 3 x 4 ## group variable statistic p ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ctrl weight 0.957 0.747 ## 2 trt1 weight 0.930 0.452 ## 3 trt2 weight 0.941 0.564 Tanto el control como los dos tratamientos tienen un valor-p \\(&gt;\\) 0.05, lo que indica que se distribuyen de manera normal. El estadístico que obtenemos se conoce como \\(W\\) y entre más cercano sea su valor a 1 más evidencia existe de que se trata de datos que se distribuyen de manera normal. Otra opción es realizar la prueba de Shapiro-Wilk con la función integrada en R, de nombre bastante similar, llamada shapiro.test(). Para esta prueba no es necesario agrupar los datos por tratamiento. PlantGrowth$weight %&gt;% shapiro.test ## ## Shapiro-Wilk normality test ## ## data: . ## W = 0.98268, p-value = 0.8915 Como podemos ver, el valor-p = 0.8915, lo que indica que nuestros datos se distribuyen de manera normal. Algo importante a tener en consideración es que para muestras con \\(n &gt; 50\\) es recomendable utilizar otra prueba ya que la prueba de Shapiro-Wilk es sensible a pequeñas desviaciones de la normalidad para muestras grandes. Una alternativa es la utilización de gráficos Q-Q o Q-Q plot. Los gráficos Q-Q nos muestran la correlación que existe entre una muestra dada y la distribución normal. Utilizaremos la librería ggpubr y la función ggqqplot(). library(ggpubr) ggqqplot(PlantGrowth$weight) + xlab(&quot;Teórico&quot;) + ylab(&quot;Muestra&quot;) Figura 6.3: Gráfico Q-Q que muestra la distribución normal de datos. Este gráfico nos muestra una distribución normal teórica vs. la de nuestros datos. Como podemos ver, todos los puntos caen dentro del intervalo de confianza al 95% de la recta, lo que quiere decir que nuestros datos se distribuyen de manera normal. Esto confirma los resultados obtenidos con la prueba de Shapiro-Wilk. Otra opción sería ver la gráfica de densidad para identificar la forma de la distribución. ggdensity(PlantGrowth$weight, fill = &quot;lightblue&quot;) + xlab(&quot;Peso&quot;) + ylab(&quot;Densidad&quot;) Figura 6.4: Gráfico de densidad que muestra una ligera forma de campana, lo que indica una distribución normal de los datos. 6.2 Prueba de homocedasticidad Para la prueba de homocedasticidad existen varias aproximaciones. En este caso veremos pruebas estadísticas, ya que existen pruebas que se pueden realizar una vez realizamos el ANOVA. La prueba a utilizar es la prueba de Bartlett, que en R se escribe bartlett.test(). Es una prueba relativamente sencilla de realizar. bartlett.test(weight ~ group, PlantGrowth) ## ## Bartlett test of homogeneity of variances ## ## data: weight by group ## Bartlett&#39;s K-squared = 2.8786, df = 2, p-value = 0.2371 Indicamos que la variable weight va a ser evaluada bajo la variable group. Como resultados tenemos el estadístico Bartlett, los grados de libertad y el valor-p, que en este caso resulto ser valor-p \\(&gt;\\) 0.05 lo que significa que aceptamos la hipótesis de que nuestros datos tienen varianzas iguales. Un valor-p \\(&lt;\\) 0.05 indicaría que nuestros datos NO tienen varianzas iguales. Otra prueba que podemos utilizar que viene en la librería car es la prueba de Levene. Utilizamos la función leveneTest(). library(car) leveneTest(weight ~ group, PlantGrowth, mean) ## Levene&#39;s Test for Homogeneity of Variance (center = mean) ## Df F value Pr(&gt;F) ## group 2 1.237 0.3062 ## 27 En este caso nuestro valor-p es mayor a 0.05 (indicado en el outpot como Pr(&gt;F)) lo que indica que no hay diferencias en las varianzas de nuestras muestras. Es importante que en nuestro último argumento (center) escribamos que queremos que los calculos se realicen con la media (center = mean). Si utilizamos la mediana, haremos una prueba modificada de Levene conocida como prueba de Brown-Forsythe, que es la prueba que realiza por defecto si no escribimos mean. leveneTest(weight ~ group, PlantGrowth) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 1.1192 0.3412 ## 27 Podemos ver que medida de tendencia central utilizó en la consola, después del título de la prueba. Una vez que hemos corroborado que nuestros datos presentan homocedasticidad, distribución normal y sabemos que son independientes, podemos proceder a hacer el ANOVA. 6.3 Análisis de varianza (ANOVA de una vía) Algo importante es que R requiere que las variables predictoras sean clasificadas como grupos de factores. Si corroboramos en nuestros datos de PlantGrowth veremos que efectivamente la variable predictora (el tratamiento) se encuentra como factor. str(PlantGrowth) ## &#39;data.frame&#39;: 30 obs. of 2 variables: ## $ weight: num 4.17 5.58 5.18 6.11 4.5 4.61 5.17 4.53 5.33 5.14 ... ## $ group : Factor w/ 3 levels &quot;ctrl&quot;,&quot;trt1&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... En caso de que nuestros datos no se encuentren como factores podemos transformarlos con la función as.factor() o as_factor(). datos &lt;- as.factor(c(&quot;Tratamiento1&quot;, &quot;Tratamiento2&quot;, &quot;Control&quot;)) str(datos) ## Factor w/ 3 levels &quot;Control&quot;,&quot;Tratamiento1&quot;,..: 2 3 1 Cuando nos referimos a un ANOVA de una vía decimos que solamente consideramos una variable predictora o independiente. También se le conoce como ANOVA de un factor. En este caso, para la base de datos de PlantGrowth solo estamos considerando el tratamiento, por lo tanto lo lógico es hacer un ANOVA de una vía. Sin emabrgo, si además del tratamiento tuvieramos otra variable como la cantidad de luz, podríamos considerar hacer un ANOVA de dos vías. El ANOVA parte de la hipótesis de que todas las muestras vienen de una población con la misma media, es decir \\(H_0\\): Las medias de todas las muestras son iguales: \\(\\mu_1 = \\mu_2 = \\mu_3 = ... = \\mu_n\\). \\(H_A\\): Al menos una de las medias de las muestras es distinta: \\(\\mu_1 \\neq \\mu_n\\). Antes de empezar a hacer el análisis recordemos un poco los fundamentos del ANOVA. Empecemos con cierta notación que nos será útil. \\(k\\) = número de grupos/poblaciones/tratamientos. \\(n_i\\) = número de muestras en el grupo/tratamiento i. \\(x_{ij}\\) = el j-ésimo valor en el i-ésimo grupo/tratamiento. \\(\\overline{x}_i\\) = la media del i-ésimo grupo/tratamiento. \\(s_i\\) = la desviación estándar del i-ésimo grupo/tratamiento. \\(n\\) = el número total de muestras/observaciones independientemente del grupo. \\(\\overline{x}\\) = la media global de todos los grupos/poblaciones/tratamientos independientemente del grupo. El estadístico que calcula el ANOVA se conoce como \\(F_{ratio}\\), ya que es una relación entre dos valores: los cuadrados medios entre grupos (\\(CM_{entre}\\)) y los cuadrados medios dentro de los grupos (\\(MS_{dentro}\\)). Para calcular el \\(F_{ratio}\\) utilizamos la ecuación (eq:Fratio). \\[\\begin{equation} F_{ratio} = \\frac{CM_{entre}}{CM_{dentro}} \\tag{6.1} \\end{equation}\\] Cada uno de estos términos tiene su propia fórmula. \\[\\begin{equation} CM_{entre} = \\frac{SC_{entre}}{gl_{entre}} \\tag{6.2} \\end{equation}\\] Dónde \\(gl_{entre}\\) hace referencia a los grados de libertad entre grupos y \\(SC_{entre}\\) hace referencia a la suma de cuadrados entre grupos. \\[\\begin{equation} CM_{dentro} = \\frac{SC_{dentro}}{gl_{dentro}} \\tag{6.3} \\end{equation}\\] Dónde \\(gl_{dentro}\\) hace referencia a los grados de libertad dentro de los grupos** y \\(SC_{dentro}\\) hace referencia a la suma de cuadrados dentro de los grupos. Para calcular la suma de cuadrados total usamos la siguiente ecuación. La suma de cuadrados total hace referencia a la variación de todos los datos respecto de la media global (\\(\\overline{x}\\)). \\[\\begin{equation} SC_{total} = \\sum_{i = 1}^{k}\\sum_{j = 1}^{n_i}(x_{ij}-\\overline{x})^2 = SC_{entre} + SC_{dentro} \\tag{6.4} \\end{equation}\\] Pues esta suma de cuadrados total está compuesta de dos valores: la suma de cuadrados entre grupos (\\(SC_{entre}\\)) y la suma de cuadrados dentro de los grupos (\\(SC_{dentro}\\)) aunque también se le conoce como el error o los residuales. Para calcular la suma de cuadrados entre grupos usamos la siguiente ecuación. Este valor hace referencia a la variación de las medias de cada grupo (\\(\\overline{x}_i\\)) cada grupo respecto de la media global (\\(\\overline{x}\\)). \\[\\begin{equation} SC_{entre} = \\sum_{i = 1}^{k}n_{i}(\\overline{x}_{i} - \\overline{x})^2 \\tag{6.5} \\end{equation}\\] Para calcular la suma de cuadrados dentro de los grupos usamos la siguiente ecuación. Este valor hace referencia a la variación de cada muestra u observación dentro de un grupo respecto de la media de ese grupo (\\(\\overline{x}_i\\)). \\[\\begin{equation} SC_{dentro} = \\sum_{i = 1}^{k}\\sum_{j = 1}^{n_i}(x_{ij} - \\overline{x}_{i})^2 = \\sum_{i = 1}^{k}(n_i - 1)s_i^2 = SC_{total} - SC_{entre} \\tag{6.6} \\end{equation}\\] El calculo de los grados de libertad es algo relativamente sencillo y se puede hacer de la siguiente manera. Para los grados de libertad entre grupos: \\[\\begin{equation} gl_{entre} = k - 1 \\tag{6.7} \\end{equation}\\] Para los grados de libertad dentro de los grupos: \\[\\begin{equation} gl_{dentro} = n - k \\tag{6.8} \\end{equation}\\] Para los grados de libertad totales: \\[\\begin{equation} gl_{total} = n - 1 \\tag{6.9} \\end{equation}\\] Algo recomendado de hacer es construir una tabla con cada uno de los pasos a seguir con sus respectivas fórmulas. Los resultados que se presenta el ANOVA en R tiene un formato similar. Tabla 6.1: Tabla de ANOVA Fuentes gl SC CM F_ratio Entre grupos (Tratamientos) \\(k - 1\\) \\(\\sum_{i = 1}^{k}n_{i}(\\overline{x}_{i} - \\overline{x})^2\\) \\(\\frac{SC_{entre}}{gl_{entre}}\\) \\(\\frac{CM_{entre}}{CM_{dentro}}\\) Dentro de grupos (Residuales) \\(n - k\\) \\(\\sum_{i = 1}^{k}\\sum_{j = 1}^{n_i}(x_{ij} - \\overline{x}_{i})^2\\) \\(\\frac{SC_{dentro}}{gl_{dentro}}\\) Total \\(n - 1\\) \\(\\sum_{i = 1}^{k}\\sum_{j = 1}^{n_i}(x_{ij}-\\overline{x})^2\\) 6.3.1 ANOVA en R Una vez vistos los calculos necesarios para obtener el estadístico \\(F_{ratio}\\) podemos hacer el ANOVA utilizando la función aov(). La función de ANOVA en R tiene una notación particular; primero escribimos la variable dependiente (en el caso de nuestros datos de PlantGrowth, el peso), posteriormente escribimos el símbolo ~ que significa explicado por seguido de nuestra variable independiente, en este caso, el tratamiento. Al final escribimos la base de datos de donde tomar estas variables. anova.plantas &lt;- aov(weight ~ group, PlantGrowth) anova.plantas ## Call: ## aov(formula = weight ~ group, data = PlantGrowth) ## ## Terms: ## group Residuals ## Sum of Squares 3.76634 10.49209 ## Deg. of Freedom 2 27 ## ## Residual standard error: 0.6233746 ## Estimated effects may be unbalanced Para observar el valor-p podemos utilizar la función summary() para obtener una tabla de ANOVA. summary(anova.plantas) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## group 2 3.766 1.8832 4.846 0.0159 * ## Residuals 27 10.492 0.3886 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Df corresponde a los grados de libertad, Sum Sq corresponde a la suma de cuadrados, Mean Sq corresponde a los cuadrados medios y F value corresponde al valor F calculado. Pr(&gt;F) corresponde al valor-p. En este caso nuestro valor-p \\(&lt;\\) 0.05 por lo que sabemos que hay diferencias entre grupos. Si quisieramos exportar esto a una tabla necesitamos utilizar la librería broom. library(broom) tabla.aov.plantas &lt;- tidy(anova.plantas) Tabla 6.2: Resultados del ANOVA de tratamientos de plantas term df sumsq meansq statistic p.value group 2 3.76634 1.8831700 4.846088 0.01591 Residuals 27 10.49209 0.3885959 Después de hacer el ANOVA podemos comprobar la distribución normal con los residuales. Para esto tenemos que crear una variable nueva. Esto lo podemos hacer también con la librería broom y la función augment(). residuales &lt;- anova.plantas$residuals hist(residuales, xlab = &quot;Residuales&quot;, ylab = &quot;Frecuencia&quot;, main = &quot;Histograma de Residuales&quot;) Figura 6.5: Histograma de residuales del ANOVA mostrando distribución normal. tabla.aov.plantas2 &lt;- augment(anova.plantas) hist(tabla.aov.plantas2$.resid, xlab = &quot;Residuales&quot;, ylab = &quot;Frecuencia&quot;, main = &quot;Histograma de Residuales&quot;) Figura 6.6: Histograma de residuales del ANOVA a partir de los residuales obtenidos por la función augment(). Como podemos ver, los residuales tienen una distribución más o menos normal. Esto confirma lo que habíamos visto en las pruebas de normalidad y homocedasticidad. Podemos incluso mostrar la gráfica Q-Q de los residuales. ggqqplot(tabla.aov.plantas2$.resid) + xlab(&quot;Teórico&quot;) + ylab(&quot;Residuales&quot;) Figura 6.7: Gráfico Q-Q de los residuales obtenidos por el ANOVA. 6.4 Pruebas post hoc Palacio, F. X., Apodaca, M. J., &amp; Crisci, J. V. (2020). Análisis multivariado para datos biológicos. Teoría y su aplicación utilizando el lenguaje r. Fundación Azara. "]]
