[["análisis-de-varianza-anova.html", "Lección 3 Análisis de Varianza (ANOVA) 3.1 Prueba de normalidad 3.2 Prueba de homocedasticidad", " Lección 3 Análisis de Varianza (ANOVA) Para realizar un análisis de varianza o ANOVA es necesario cumplir con ciertos supuestos. Estos supuestos son similares para otro tipo de pruebas y se encuentran descritas en la sigueinte lista: Distribución normal de los datos. Homocedasticidad (varianzas iguales). Datos independientes. La distribución normal y la homocedasticidad son hasta cierto punto flexibles. Sin embargo, el ANOVA es sumamente sentitivo a muestras no independientes. Pese a su nombre, el análisis de varianza en realidad busca diferencias en las medias (\\(\\mu\\)) de las muestras. Antes de hacer el ANOVa debemos buscar una manera de comprobar la distribución normal y la homocedasticidad de los datos. Esto es relativamente sencillo de hacer. 3.1 Prueba de normalidad Una de las pruebas de normalidad más utilizadas es la prueba de Shapiro-Wilk. El resultado de la prueba de Shapiro-Wilk es un valor-p que se puede interpretar de la siguiente manera: Valor-p \\(&lt;\\) 0.01: No normalidad. Valor-p \\(&lt;\\) 0.05: No normalidad. Valor-p \\(\\ge\\) 0.05: Sin evidencia concluyente de no normalidad. Usualmente un valor-p \\(&lt;\\) 0.05 es suficiente para indicar que nuestros datos no se distribuyen de manera normal. Esta base de datos incluye 2 variables, los valores del peso y el tratamiento que recibieron las plantas. Para esta ocasión vamos a trabajar con la base de datos PlantGrowth que viene incluida en R. data(&quot;PlantGrowth&quot;) Vamos a realizar una gráfica de nuestros datos para darnos una idea de su comportamiento. library(ggplot2) ggplot(PlantGrowth) + geom_point(aes(group, weight, color = group)) + xlab(&quot;Grupo&quot;) + ylab(&quot;Peso&quot;) + scale_color_discrete(name = &quot;Tratamientos&quot;, labels = c(&quot;Control&quot;, &quot;Tratamiento 1&quot;, &quot;Tratamiento 2&quot;)) + theme_classic() Figura 3.1: Gráfica con los distintos tratamientos. Otra forma de visualizar los datos es con un boxplot que puede ir dándonos idea más o menos de cómo se distribuyen nuestros datos. library(ggplot2) ggplot(PlantGrowth) + geom_boxplot(aes(group, weight, fill = group)) + xlab(&quot;Grupo&quot;) + ylab(&quot;Peso&quot;) + scale_fill_discrete(name = &quot;Tratamientos&quot;, labels = c(&quot;Control&quot;, &quot;Tratamiento 1&quot;, &quot;Tratamiento 2&quot;)) + theme_classic() Figura 3.2: Graficos de boxplot para visualización de las distribuciones de los datos. Computar la prueba de normalidad de Shapiro-Wilk sumamente sencillo y se hace con la función shapiro_test() de la librería rstatix. Para esto primero tenemos que agrupar nuestros datos por tratamientos con la función group_by() del paquete de dplyr. library(tidyverse) library(rstatix) ## Warning: package &#39;rstatix&#39; was built under R version 4.0.4 ## ## Attaching package: &#39;rstatix&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## filter PlantGrowth %&gt;% group_by(group) %&gt;% shapiro_test(weight) #Agrupamos los datos por tratamiento. ## # A tibble: 3 x 4 ## group variable statistic p ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ctrl weight 0.957 0.747 ## 2 trt1 weight 0.930 0.452 ## 3 trt2 weight 0.941 0.564 Tanto el control como los dos tratamientos tienen un valor-p \\(&gt;\\) 0.05, lo que indica que se distribuyen de manera normal. El estadístico que obtenemos se conoce como \\(W\\) y entre más cercano sea su valor a 1 más evidencia existe de que se trata de datos que se distribuyen de manera normal. Otra opción es realizar la prueba de Shapiro-Wilk con la función integrada en R, de nombre bastante similar, llamada shapiro.test(). Para esta prueba no es necesario agrupar los datos por tratamiento. PlantGrowth$weight %&gt;% shapiro.test ## ## Shapiro-Wilk normality test ## ## data: . ## W = 0.98268, p-value = 0.8915 Como podemos ver, el valor-p = 0.8915, lo que indica que nuestros datos se distribuyen de manera normal. Algo importante a tener en consideración es que para muestras con \\(n &gt; 50\\) es recomendable utilizar otra prueba ya que la prueba de Shapiro-Wilk es sensible a pequeñas desviaciones de la normalidad para muestras grandes. Una alternativa es la utilización de gráficos Q-Q o Q-Q plot. Los gráficos Q-Q nos muestran la correlación que existe entre una muestra dada y la distribución normal. Utilizaremos la librería ggpubr y la función ggqqplot(). library(ggpubr) ## Warning: package &#39;ggpubr&#39; was built under R version 4.0.4 ggqqplot(PlantGrowth$weight) + xlab(&quot;Teórico&quot;) + ylab(&quot;Muestra&quot;) Figura 3.3: Gráfico Q-Q que muestra la distribución normal de datos. Este gráfico nos muestra una distribución normal teórica vs. la de nuestros datos. Como podemos ver, todos los puntos caen dentro del intervalo de confianza al 95% de la recta, lo que quiere decir que nuestros datos se distribuyen de manera normal. Esto confirma los resultados obtenidos con la prueba de Shapiro-Wilk. Otra opción sería ver la gráfica de densidad para identificar la forma de la distribución. ggdensity(PlantGrowth$weight, fill = &quot;lightblue&quot;) + xlab(&quot;Peso&quot;) + ylab(&quot;Densidad&quot;) Figura 3.4: Gráfico de densidad que muestra una ligera forma de campana, lo que indica una distribución normal de los datos. 3.2 Prueba de homocedasticidad Para la prueba de homocedasticidad existen varias aproximaciones. En este caso veremos pruebas estadísticas, ya que existen pruebas que se pueden realizar una vez realizamos el ANOVA. La prueba a utilizar es la prueba de Bartlett, que en R se escribe bartlett.test(). Es una prueba relativamente sencilla de realizar. bartlett.test(weight ~ group, PlantGrowth) ## ## Bartlett test of homogeneity of variances ## ## data: weight by group ## Bartlett&#39;s K-squared = 2.8786, df = 2, p-value = 0.2371 Indicamos que la variable weight va a ser evaluada bajo la variable group. Como resultados tenemos el estadístico Bartlett, los grados de libertad y el valor-p, que en este caso resulto ser valor-p \\(&gt;\\) 0.05 lo que significa que aceptamos la hipótesis de que nuestros datos tienen varianzas iguales. Un valor-p \\(&lt;\\) 0.05 indicaría que nuestros datos NO tienen varianzas iguales. Otra prueba que podemos utilizar que viene en la librería car es la prueba de Levene. Utilizamos la función leveneTest(). library(car) leveneTest(weight ~ group, PlantGrowth, mean) ## Levene&#39;s Test for Homogeneity of Variance (center = mean) ## Df F value Pr(&gt;F) ## group 2 1.237 0.3062 ## 27 En este caso nuestro valor-p es mayor a 0.05 (indicado en el outpot como Pr(&gt;F)) lo que indica que no hay diferencias en las varianzas de nuestras muestras. Es importante que en nuestro último argumento (center) escribamos que queremos que los calculos se realicen con la media (center = mean). Si utilizamos la mediana, haremos una prueba modificada de Levene conocida como prueba de Brown-Forsythe, que es la prueba que realiza por defecto si no escribimos mean. leveneTest(weight ~ group, PlantGrowth) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 1.1192 0.3412 ## 27 Podemos ver que medida de tendencia central utilizó en la consola, después del título de la prueba. Una vez que hemos corroborado que nuestros datos presentan homocedasticidad, distribución normal y sabemos que son independientes, podemos proceder a hacer el ANOVA. ## "]]
