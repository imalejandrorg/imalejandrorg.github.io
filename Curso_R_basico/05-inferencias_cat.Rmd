---
output:
  bookdown::html_document2:
    fig.caption: yes
editor_options: 
  markdown: 
    wrap: sentence
---

# Inferencia de datos categóricos

```{r include=FALSE}
library(knitr)
library(bookdown)
library(tidyverse)
library(kableExtra)
library(ggthemes)
library(cowplot)
library(ggpubr)
library(latex2exp)
library(kableExtra)
library(broom)
```

## Distribuciones de una muestra

En esta sección consideraremos **variables categóricas**, es decir, variables que solamente tienen dos posibles valores, y su distribución muestral de la proporción de la muestra.
Normalmente, al tomar muestras de una población dicotómica grande, un estimado de la proporción, $p$, es la muestra de la proporción $\hat{p} = \frac{x}{n}$, donde $x$ es el número de observaciones en la muestra que cumplen con el atributo de interés, y $n$ es el tamaño de muestra.

La proporción de Wilson ajustada a la muestra, $\tilde{p}$, es otro estimado que utiliza la fórmula \@ref(eq:wilson).
Esto equivale a sesgar la estimación hacia el valor 1/2.

\begin{equation}
\tilde{p} = \frac{x + 2}{n + 4}
(\#eq:wilson)
\end{equation}

La distribución binomial determina la distribución muestral de $\tilde{P}$.
Veamos cómo funciona esto con un ejemplo.

> **Ejemplo:** En una región de Estados Unidos, el 17% de las máquinas dispensadoras de bebidas están contaminadas por la bacteria *Chryseobacterium meningosepticum*.
> Imaginemos que examinamos una muestra de dos máquinas dispensadoras.
> La probabilidad de tener dos máquinas contaminadas es $0.17 * 0.17 = 0.0289$, la probabilidad de que ninguna este contaminada es de $1-0.17 * 1-0.17$ y la probabilidad de que una este contaminada y la otra no es $0.17 * (1-0.17) + 0.17 * (1-0.17)$.

Una muestra que contenga cero máquinas contaminadas, $\tilde{p} = \frac{0+2}{2+4} = 0.33$ ocurre con una probabilidad de 0.6889, una muestra con una máquina contaminada, $\tilde{p} = \frac{1+2}{2+4} = 0.5$ ocurre con una probabilidad de 0.2822 y una muestra con dos máquinas contaminadas, $\tilde{p} = \frac{2+2}{2+4} = 0.67$ ocurre con una probabilidad de 0.0289.
Por ende, hay un 68.89% de probabilidad de que $\tilde{P}$ sea igual a 0.33, un 28% de que $\tilde{P}$ sea igual a 0.5 y 3% de que $\tilde{P}$ sea igual a 0.67.

Imaginemos ahora que nuestra muestra pasa de $n = 2$ a $n = 20$, para encontrar la probabilidad de cuántas máquinas podríamos esperar que estén contaminadas en nuestra muestra, acudimos a la distribución binomial.
Por ejemplo, para calcular que 5 de las 20 máquinas están contaminadas usamos $p = 0.17$ y $n = 20$.

```{r}
dbinom(5, 20, 0.17)
```

Como vemos, la probabilidad de obtener 5 máquinas contaminadas es 0.1345, ahora, usando $\tilde{P}$, una muestra con 5 máquinas contaminadas sería $\tilde{p} = \frac{5+2}{20+4} = 0.2917$, por lo que $P(\tilde{P} = 0.2917) = 0.1345$.
Con la distribución binomial, podemos determinar toda la distribución muestral de $\tilde{P}$.

Por ejemplo, podemos preguntar *¿Cuál es la probabilidad de que no más de 5 máquinas estén contaminadas?*

```{r}
pbinom(5, 20, 0.17)
```

Como vemos, la probabilidad de que no más de 5 máquinas estén contaminadas es de 0.8902245.
Y como $\tilde{p} = \frac{5+2}{20+4} = 0.2917$ entonces $P(\tilde{P} \leq 0.2917) = 0.8902$.
La distribución muestral de $\tilde{P}$ se puede utilizar para predecir cuánto error de muestreo esperar en nuestro estimado.
De igual manera, entre mayor sea nuestro $n$ mayor posibilidades hay de que $\tilde{P}$ se encuentre cercano a $p$.

Para la construcción de **intervalos de confianza** de la proporción de una población, necesitamos encontrar el error estándar de $\tilde{P}$.
Para eso utilizamos la siguiente fórmula (para intervalos al 95%).


\begin{equation}
SE_\tilde{p} = \sqrt{\frac{\tilde{p}(1-\tilde{p})}{n + 4}}
(\#eq:pse)
\end{equation}

Posteriormente, realizamos el intervalo de confianza correspondiente con la siguiente fórmula (esto para un intervalo de confianza al 95%).


\begin{equation}
\tilde{p} \pm 1.96 \times SE_{\tilde{p}}
(\#eq:pic)
\end{equation}

Al igual que con otros métodos, podemos construir un intervalo de confianza unilateral si así lo deseamos.
Para eso podemos utilizar la función `qnorm()` en la cuál indicamos el valor de densidad (o probabilidad) que deseamos y así obtener un valor Z.

```{r}
qnorm(0.95, 0, 1)
```

Como podemos ver, para casos de intervalos de confianza unilaterales al 95% utilizaríamos un multiplicador de 1.645.


\begin{equation}
\tilde{p} \pm 1.645 \times SE_{\tilde{p}}
(\#eq:pic2)
\end{equation}

Las fórmulas para intervalos de confianza generales son las siguientes:


\begin{equation}
\tilde{p} \pm z_{\alpha/2} \times SE_{\tilde{p}}
(\#eq:pic2)
\end{equation}

\begin{equation}
\tilde{p} = \frac{x + 0.5(z^2_{\alpha/2})}{n + z^2_{\alpha/2}}
(\#eq:wilson2)
\end{equation}

\begin{equation}
SE_\tilde{p} = \sqrt{\frac{\tilde{p}(1-\tilde{p})}{n + z^2_{\alpha/2}}}
(\#eq:pse2)
\end{equation}

## Prueba de Chi-cuadrada

Una **prueba de bondad de ajuste** se utiliza para ver la compatibilidad de los datos con una distribución o $H_0$ específica.
Una de las más utilizadas es la **prueba de** $\chi^2$ (léase chi-cuadrada).
Para esto se utilizan frecuencias absolutas de nuestros datos.
Para cada nivel de categoría, $i$, dejamos que $o_i$ represente la frecuencia observada y $e_i$ la frecuencia esperada, es decir, la frecuencia que esperaríamos obtener bajo la $H_0$.
Las frecuencias esperadas $e_i$ se obtienen multiplicando las probabilidades dadas por la $H_0$ por $n$.
Posteriormente utilizamos la fórmula \@ref(eq:chi) para calcular nuestro estadístico de prueba.


\begin{equation}
\chi^2 = \sum_{i = 1}^{k}\frac{(o_i - e_i)^2}{e_i}
(\#eq:chi)
\end{equation}

Donde $k$ es el número total de categorías e $i$ es la *i*-ésima observación.

> **Ejemplo:** Después de seis meses de un incendio, los investigadores muestrearon una parcela de 3000 acres al rededor del área quemada.
> La dividieron en cuatro regiones: (1) el área cercana al centro del incendio, (2) el área interior cercana al incendio, (3) el área exterior cercana al incendio y (4) área fuera de la zona quemada.
> La $H_0$ es que los venados no muestran preferencia por alguna de las áreas.
> La $H_A$ es que muestran cierta preferencia por alguna de las áreas.

```{r}
Area <- c(520, 210, 240, 2030)
Zona <- c("Área interior", "Área exterior", "Borde exterior", "No quemado")
Proporcion <- round(Area/sum(Area), 3)

Datos <- data.frame(Zona, Area, Proporcion)
```

```{r Ejemplo1, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
Datos %>% 
  knitr::kable("html", align = c("c", "c"), caption = "Áreas quemadas y no quemadas", col.names = c("Zona", "Área", "Proporción")) %>%
  kableExtra::kable_classic(lightable_options = "striped", full_width = F) %>% 
  column_spec(1:3, width_min = "4cm")
```

Si la $H_0$ es verdadera, entonces


\begin{aligned}
H_0: P(Área \space interior) = \frac{520}{3000} = 0.173 \\
P(Área \space exterior) = \frac{210}{3000} = 0.070 \\
P(Borde \space  exterior) = \frac{240}{3000} = 0.080 \\
P(No \space quemado) = \frac{2030}{3000} = 0.677
\end{aligned}

Entonces la $H_A$ sería


\begin{aligned}
H_A: P(Área \space interior) \ne 0.173 \\
P(Área \space exterior) \ne 0.070 \\
P(Borde \space  exterior) \ne 0.080 \\
P(No \space quemado) \ne 0.677
\end{aligned}

Los investigadores encontraron 75 venados en el área, distribuidos en distintas zonas como se muestra a continuación.

```{r}
Venados <- c(2, 12, 18, 43)
Datos <- data.frame(Datos, Venados)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align='center', fig.cap="Zonas de avistamientos de venados, $n = 75$."}
ggplot(Datos, aes(reorder(Zona, Venados), Venados)) + geom_bar(stat = "identity", color = "Gray20", fill = "Gray80", width = 0.7) +
  xlab("Zona") +
  ylab("No. de venados") +
  theme_classic()
```

```{r Ejemplo1a, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
Datos %>% 
  knitr::kable("html", align = c("c", "c"), caption = "Áreas quemadas y no quemadas y el número de venados observados", col.names = c("Zona", "Área", "Proporción", "No. de venados")) %>%
  kableExtra::kable_classic(lightable_options = "striped", full_width = F) %>% 
  column_spec(1:3, width_min = "4cm")
```

Para este caso, las probabilidades estimadas (denotadas como $\hat{p}$) son


\begin{align}
\hat{P}(Área \space interior) = \frac{2}{75} = 0.027 \\
\hat{P}(Área \space exterior) = \frac{12}{75} = 0.160 \\
\hat{P}(Borde \space  exterior) = \frac{18}{75} = 0.240 \\
\hat{P}(No \space quemado) = \frac{43}{75} = 0.573
\end{align}

Estas las podemos calcular fácilmente.

```{r}
Prop_venados <- round(Venados/sum(Venados), 3)
Datos <- data.frame(Datos, Prop_venados)
```

```{r Ejemplo1b, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
Datos %>% 
  knitr::kable("html", align = c("c", "c"), caption = "Áreas quemadas y no quemadas y el número de venados observados con su proporción", col.names = c("Zona", "Área", "Proporción esperada", "No. de venados", "Proporción observada")) %>%
  kableExtra::kable_classic(lightable_options = "striped", full_width = F) %>% 
  column_spec(1:3, width_min = "3.5cm")
```

Como podemos ver, las proporciones observadas $\hat{P}$ difieren de las que esperaríamos en el modelo de la $H_0$.

```{r Ejemplo1c, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align='center', fig.cap="Valores observados contra esperados en las proporciones de venados en zonas quemadas."}
Condicion <- c(rep("Esperado", 4), rep("Observado", 4))
Zona1 <- rep(c("Área interior", "Área exterior", "Borde exterior", "No quemado"), 2)
Prop <- c(Proporcion, Prop_venados)

graph <- data.frame(Condicion, Zona1, Prop)

ggplot(graph, aes(fill = reorder(Zona1, Prop), y = Prop, x = Condicion)) + 
  geom_bar(position = position_fill(reverse = T), stack = "dodge", stat = "identity",  color = "Grey5", width = 0.6) +
  scale_fill_grey(start = 0.2, end = 0.8) +
  xlab("") +
  ylab("Proporción") +
  labs(fill = "Zona") +
  theme_classic()
```

Ahora, para aplicar la fórmula de $\chi^2$ necesitamos los valores absolutos de nuestros datos, para esto simplemente multiplicamos la probabilidad calculada por la $H_0$, $p * n$.

```{r}
#Usamos la función sum() para sumar todos los valores de la variable "Venados".
Venados_esperados <- Proporcion * sum(Datos$Venados) 
Venados_esperados
```

Como podemos ver, los valores son aproximadamente 13, 5.25, 6 y 50.78.
Ahora simplemente aplicamos la fórmula para nuestros datos.


\begin{align}
\chi_s^2 = \frac{(2-13)^2}{13} + \frac{(12-5.25)^2}{5.25} + \frac{(18-6)^2}{6} + \frac{(43-50.78)^2}{50.78} = 43.2
\end{align}

Ahora tenemos que considerar la distribución nula de $\chi_s^2$, que es la distribución muestral que se sigue en caso de que nuestra $H_0$ sea verdadera.
Esta distribución muestral sigue la distribución de chi-cuadrada $\chi^2$ cuando el tamaño de muestra es suficientemente grande.
La forma de la distribución de $\chi^2$ depende de los grados de libertad.

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align='center', fig.cap="Distribución de $\\chi^2$ con $df = 5$ en azul, $df = 8$ en rojo y $df = 10$ en verde."}

ggplot(data.frame(x = c(0, 30)), aes(x = x)) +
  stat_function(fun = dchisq, args = list(df = 5), size = 0.6, color = "blue") +
  stat_function(fun = dchisq, args = list(df = 8), size = 0.6, color = "red") +
  stat_function(fun = dchisq, args = list(df = 10), size = 0.6, color = "darkgreen") +
  geom_text(aes(x = 20, label = "df = 5", y = 0.1), color = "blue") +
  geom_text(aes(x = 20, label = "df = 8", y = 0.09), color = "red") +
  geom_text(aes(x = 20.2, label = "df = 10", y = 0.08), color = "darkgreen") +
  scale_y_continuous(breaks = NULL) +
  ylab("") +
  xlab("") +
  theme_minimal_hgrid(color = "black")

```

Al igual que las demás distribuciones de probabilidad en `R`, tenemos una serie de comandos para encontrar los valores de una distribución de chi-cuadrada fácilmente.

\-`dchisq()` nos da un valor de densidad en determinado punto de la distribución de $\chi^2$.

\-`pchisq()` nos da un valor de densidad acumulado hasta cierto punto en la distribución de $\chi^2$ (área debajo de la curva).

\-`qchisq()` toma el valor de densidad que le ponemos como primer argumento y nos da como regreso un número cuya densidad acumulada empate con el valor de densidad ingresado.

\-`rchisq()` genera cierta cantidad de número aleatorios de acuerdo al valor de densidad.

Sin embargo en este caso, en lugar de contar con el argumento `n` para el tamaño de muestra, contamos con otro argumento `df` para los grados de libertad.

Por ejemplo, supongamos que quisiéramos encontrar el valor crítico $\chi_{5,0.05}^2$ cuando $df = 5$, para esto utilizamos la función `qchisq()`.

```{r}
qchisq(0.95, 5)
```

Como podemos ver, el valor crítico es 11.07.
Esto corresponde a un área de 0.05 por encima de la cola de la distribución de $\chi^2$.

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

ggplot(data.frame(x = c(0, 30)), aes(x = x)) +
  stat_function(fun = dchisq, args = list(df = 5), geom = "area", fill = "lightblue", xlim = c(11.07,30)) +
  stat_function(fun = dchisq, args = list(df = 5), size = 0.6) +
  geom_vline(aes(xintercept = 11.07), linetype = "dashed", size = 0.35) +
  geom_text(aes(x = 15, y = 0.03, label = "Área = 0.05")) +
  geom_text(aes(x = 5, y = 0.03, label = "Área = 0.95")) +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(limit = c(0, 30), breaks = c(0, 5, 11.07, 15, 20, 25, 30), labels = c("0" = "0", "5" = "5",  "11.07" = parse(text = TeX("$\\chi_{5, 0.025}^2$")), "15" = "15", "20" = "20", "25" = "25", "30" = "30")) +
  ylab("") +
  xlab("") +
  theme_minimal_hgrid(color = "black")

```

El cálculo de los grados de libertad $df$ para una distribución de $\chi^2$ depende del número de categorías, $k$.


\begin{align}
df = k - 1
(\#eq:chidf)
\end{align}

Siguiendo el ejemplo de los venados, en este caso tenemos $k = 4$ por lo que $df = 4 - 1 = 3$.
Ya que el valor que habíamos obtenido de nuestra fórmula de $\chi_s^2 = 43.2$, buscaremos el área debajo de la curva correspondiente a este valor.

```{r}
pchisq(43.2, 3, lower.tail = F)
```

Como podemos ver el resultado es extremadamente pequeño y nuestro $valor-p < 0.0001$ por lo que tenemos evidencia para rechazar la $H_0$ y aceptar la hipótesis de que los venados prefieren ciertas zonas sobre otras.
La prueba de $\chi^2$ se puede utilizar para cualquier número de categorías $k$.

Ahora todo esto se facilita gracias a la función `chisq.test()` que viene incluida en `R`.

Para realizar la prueba de Chi-cuadrada con esta función, lo único que necesitamos es una variable con el valor absoluto de nuestras observaciones y otra con los valores relativos esperados como los de la tabla \@ref(tab:Ejemplo1d).

```{r}
chisq.test(Datos$Venados, Datos$Propocion)
```

Estos valores los podemos obtener de la matriz de datos que habíamos creado previamente, simplemente los seleccionamos con el símbolo `$` seguido del nombre de la variable (`$Venados` y `$Proporcion`, en mí caso).

```{r Ejemplo1d, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
Datos %>% 
  dplyr::select(-Zona, -Area, -Prop_venados) %>% 
  knitr::kable("html", align = c("c", "c"), caption = "Datos utilizados por la función `chisq.test()` en R", col.names = c("Proporción esperada", "No. de venados")) %>%
  kableExtra::kable_classic(lightable_options = "striped", full_width = F) %>% 
  column_spec(1:2, width_min = "5.2cm")
```

### Hipótesis compuestas y direccionales

Hay que darnos cuenta que en el ejemplo de los venados, nuestras hipótesis son **hipótesis compuestas**, es decir, hacen múltiples afirmaciones, a diferencia de las hipótesis que hacíamos en las pruebas de $t$ ($H_0: \mu_1 = \mu_2$).
Las primeras tres afiramciones de nuestra hipótesis nula $H_0$ son independientes, $P(Área \space interior) = 0.173$, $P(Área \space exterior) = 0.070$, $P(Borde \space exterior) = 0.080$ pero nuestra última afirmación, $P(No \space quemado) = 0.677$, es **dependiente** de las demás afirmaciones realizadas.
Cuando esto ocurre, la hipótesis alternativa es necesariamente no direccional.
Otra cosa interesante es que cuando se rechaza la $H_0$, la prueba no nos dice la dirección de la conclusión.

En cambio, cuando una variable es dicotómica, la $H_0$ no es compuesta y por lo tanto, alternativas direccionales o conclusiones direccionales no suponen un problema.
Para una variable dicotómica, una prueba de hipótesis direccional de Chi-cuadrada se realizaría de la misma manera que en pruebas pasadas.

1.  Primero elegimos la direccionalidad y corroboramos que los datos se desvían de la $H_0$ en la dirección especificada por la $H_A$.
    Si es así realizamos el siguiente paso.

2.  Encontramos el valor-*p*, el cuál será la mitad de lo que sería si nuestra $H_A$ fuese no direccional.

## Prueba de Chi-cuadrada para tablas de contingencia

Una **tabla de contingencia** muestra los datos de tal manera que existe una asociación entre las variables de las filas y columnas.

> **Ejemplo:** Un grupo de 75 pacientes fueron asignados de manera aleatoria para recibir una cirugía para tratar dolores de migraña.
> La cirugía podía ser real ($n = 49$) o no ($n = 26$).
> Los cirujanos esperan una reducción en los dolores de migraña (éxito).
> En la tabla \@ref(tab:Ejercicio2a) se pueden observar los datos.

```{r}
#Creamos nuestra matriz de datos.
cirugia <- matrix(c(41, 15, 8, 11), nrow = 2, ncol = 2, byrow = T)
dimnames(cirugia) <- list(c("Éxito", "Fracaso"), c("Real", "Falsa"))
```

Como podemos ver, tenemos nuestra tabla de contingencia lista.

|             |          |           |
|-------------|----------|-----------|
|             | **Real** | **Falsa** |
| **Éxito**   | 41       | 15        |
| **Fracaso** | 8        | 11        |

Posteriormente podríamos agregar los casos totales para cada lado de nuestra tabla de contingencia.

+----------------+----------------+-----------------+----------------+
|                | **Real**       | **Falsa**       | **Total**      |
+----------------+----------------+-----------------+----------------+
| **Éxito**      | 41             | 15              | 56             |
+----------------+----------------+-----------------+----------------+
| **Fracaso**    | 8              | 11              | 19             |
+----------------+----------------+-----------------+----------------+
| **Total**      | 49             | 26              | 75             |
+----------------+----------------+-----------------+----------------+

Cuando hacemos una prueba de Chi-cuadrado para este tipo de tablas, nusetra hipótesis nula es que la probabilidad de éxito dado que la cirugía fue real es la misma que la probabilidad de éxito dado que la cirugía fue falsa, $H_0: P(Éxito|Real) = P(Éxito|Falsa)$. Como vimos en la lección de probabilidad, este tipo de probabilidad se conoce como **condicional** y predice qué tan seguido un evento ocurre bajo condiciones específicas.

\begin{equation}
P(A|B)
\end{equation}

Esta fórmula nos dice cuál es la probabilidad de que A ocurra, dado que B ha ocurrido. Cuando una probabilidad condicional se estima de los datos, normalmente se denota con el símbolo ^. 

\begin{equation}
\hat{P}(A|B)
\end{equation}

Por ejemplo, para nuestros datos:

\begin{align}
\hat{P}(Éxito|Real) = \frac{41}{49} = 0.837 \\
\hat{P}(Éxito|Falsa) = \frac{15}{26} = 0.577
\end{align}

Como podemos ver, estas probabilidades las obtenemos utilizando las columnas **Real** y **Falsa** de nuestra tabla de contingencia y sus respectivos totales. Pero, ¿es esta diferencia significativa? Para esto realizaremos la prueba de Chi-cuadrada.

**IMPORTANTE:** No es lo mismo $P(Éxito|Real)$ que $P(Real|Éxito)$. Puedes comprobarlo tú mismo.

\begin{align}
\hat{P}(Éxito|Real) = \frac{41}{49} = 0.837 \\
\hat{P}(Real|Éxito) = \frac{41}{56} = 0.7321 \\
\hat{P}(Éxito|Real) \ne \hat{P}(Real|Éxito)
\end{align}

Ahora, el primer paso para aplicar la prueba de Chi-cuadrada a nuestra tabla de contingencia es calcular las **frecuencias marginales**, es decir, las frecuencias de los totales de nuestra tabla de contingencia. Si nuestra $H_0$ es verdadera, entonces las columnas **Real** y **Falsa** son equivalentes, así que podemos agruparlas ($41 + 15$) y dividirlas sobre el total de observaciones ($\frac{56}{75} = 0.747$). Bien, ahora aplicamos esta probabilidad a nuestros valores observados para el grupo Real y Falso ($\frac{56}{75} \times 49 = 36.59$ éxitos esperados y $\frac{56}{75} \times 26 = 36.59$ éxitos esperados). De igual manera, aplicamos lo mismo para los fracasos esperados ($\frac{19}{75} = 0.253$). Para obtener nuestros fracasos esperados obtenemos, multiplicamos este valor por los de los grupos Real y Falso ($\frac{19}{75} \times 49$ fracasos esperados y $\frac{19}{75} \times 26$ fracasos esperados).

+----------------+----------------+-----------------+-----------------+
|                | **Real**       | **Falsa**       | **Total**       |
+----------------+----------------+-----------------+-----------------+
| **Éxito**      | 41 (36.59)     | 15 (19.41)      | 56              |
+----------------+----------------+-----------------+-----------------+
| **Fracaso**    | 8 (12.41)      | 11 (6.59)       | 19              |
+----------------+----------------+-----------------+-----------------+
| **Total**      | 49             | 26              | 75              |
+----------------+----------------+-----------------+-----------------+

Ya que estos calculos se realizan exclusivamente con los valores marginales, los valores esperados $e$ se pueden obtener de la siguiente manera.

\begin{align}
e = \frac{(Total \space columna) \times (Total \space fila)}{Gran \space total}
(\#eq:e)
\end{align}

Los grados de libertad para nuestra tabla de contingencia de 2x2 es de 1. ¿Por qué? Bueno, porque de las 4 celdas disponibles, solamente una de ellas es libre de variar. Ya que, por ejemplo, al determinar el valor esperado de la celda superior izquierda (36.59), el valor de la celda superior derecha tiene que ser 19.41, ya que la suma de ambas debe de ser 56. Lo mismo para la celda inferior izquierda (12.41) que al sumarse a la celda superior izquierda dan como resultado 49. Y la misma lógica aplica a la celda inferior derecha. Ya que la celda superior derecha es 19.41, la celda inferior tiene que ser 6.59 para sumar 26 en total. En este sentido, **solo una celda es libre de variar** y por ende $df = 1$ para una tabla de contingencia de 2x2.

Para este tipo de tablas, la hipótesis puede ser direccional o no direccional. En el caso de nuestro ejemplo, nos interesa saber si el efecto de la cirugía reduce el dolor de migraña (hipótesis direccional), así que al calcular el valor-*p* simplemente hay que dividirlo entre 2 y obtendremos el valor direccional.

Ahora sí, podemos aplicar la fórmula de $\chi^2$.

\begin{align}
\chi_s^2 = \frac{(41-36.59)^2}{36.59} + \frac{(15-19.41)^2}{19.41} + \frac{(8-12.41)^2}{12.41} + \frac{(11-6.59)^2}{6.59} = 6.06
\end{align}

Todo este proceso se puede hacer de manera rapidísima con la función `chisq.test()`. Lo único que tenemos que hacer es poner nuestra matriz de datos y el argumento `correct = F` para evitar aplicar correcciones.

```{r}
chisq.test(cirugia, correct = F)
```

Como vemos el valor-*p* es igual a 0.01381, pero como nuestra hipótesis es direccional debemos de dividirlo en 2.

```{r}
chisq.test(cirugia, correct = F)$p.value / 2
```

Por lo que obtenemos un $valor-p = 0.0069$. En este caso, si nuestro $\alpha = 0.01$ rechazaríamos la $H_0$ y diríamos que hay evidencias suficientes que apoyan que la cirugía real es mejor que la falsa para reducir los dolores de migraña.


## Interpretación de las tablas de contingencia

Una tabla de contingencia 2x2 se puede intepretar de dos maneras:

1. Dos muestras independientes con una variable dicotómica.

2. Una muestra con dos variable dicotómicas.

Afortunadamente, la aritmética de la prueba de Chi-cuadrada es la misma para ambos contextos, pero la intepretación de la hipótesis y las conclusiones son distintas.

En algunas tablas de contingencia las filas y columnas juegan un papel muy distinto. Por ejemplo, puede que las columnas sean un tratamiento y las filas una respuesta. En otros casos, las columnas y las filas pueden jugar papeles intercambiables.

Cuando un conjunto de datos es visto como una sola muestra con dos variable dicotómicas, la relación expresada por $H_0$ se conoce como **dependencia estadística** de las variables de columna y fila. Variables que no son independientes son llamadas **dependientes** o **asociadas**. Por eso a veces la prueba de Chi-cuadrada puede ser conocida como prueba de asociación o prueba de independencia.

>**Ejemplo:** Un antropólogo alemán que estidaba la relación entre el color de ojos y cabello observó una muestra de $n = 6800$ hombres con los resultados siguientes.

+---------------------+-------------------------+------------------------+-----------------+
|                     | **Cabello oscuro (CO)** | **Cabello claro (CC)** | **Total**       |
+=====================+=========================+========================+=================+
| **Ojo oscuro (OO)** | 726                     | 131                    | 857             |
+---------------------+-------------------------+------------------------+-----------------+
| **Ojo claro (OC)**  | 3129                    | 2814                   | 5943            |
+---------------------+-------------------------+------------------------+-----------------+
| **Total**           | 3855                    | 2945                   | 6800            |
+---------------------+-------------------------+------------------------+-----------------+

En este caso, podemos calcular las probabilidades condicional de la siguiente manera:

\begin{align}
\hat{P} = (OO|CO) = \frac{726}{3855} = 0.19 \\
\hat{P} = (OO|CC) = \frac{131}{2945} = 0.04
\end{align}

Pero la siguiente manera también es valida:

\begin{align}
\hat{P} = (CO|OO) = \frac{726}{857} = 0.85 \\
\hat{P} = (CO|OC) = \frac{3129}{5943} = 0.53
\end{align}

Por lo tanto nuestra hipótesis nula se vería de las siguientes dos maneras, ambas válidas:

\begin{align}
H_0: P(OO|CO) = P(OO|CC) \\
H_0: P(CO|OO) = P(CO|OC)
\end{align}

Esto es lo mismo que decir que $H_0: El \space color \space de \space ojos \space es \space independiente \space del \space color \space de \space cabello$ o  $H_0: El \space color \space del \space cabello \space es \space independiente \space del \space color \space de \space ojos$. Que es lo mismo que decir $H_0: El \space color \space de \space ojos \space y \space el \space color \space del \space cabello \space son \space independientes$.

La hipótesis nula de independencia puede decirse de la siguiente manera. Dos grupos, $G_1$ y $G_2$ son comparados con respecto de la probabilidad de la característica $C$. La hipótesis nula es entonces:

\begin{align}
H_0: P(C|G_1) = P(C|G_2)
\end{align}

>**Ejemplo:** Considere una especie ficticia de plantas, que se puede categorizar en pequeñas (S), y altas (T), así como resistentes (R) y no resistentes (NR) a una enfermedad.

Consideremos las siguientes $H_0$:

1. $H_0: P(R|S) = P(R|T)$

2. $H_0: P(NR|S) = P(NR|T)$

3. $H_0: P(S|R) = P(S|NR)$

4. $H_0: P(T|R) = P(T|NR)$

Todas ellas son igual de válidas. Sin embargo la siguiente hipótesis no es valida.

5. $H_0: P(R|S) = P(NR|S)$

La primer hipótesis compara dos grupos (plantas pequeñas con altas) respecto a la resistencia a la enfermedad. mientras que la hipótesis 5 es una afirmación acerca de la distribución de la resistencia a la enfermedad en solo un grupo (plantas bajas). 

Supongamos ahora que hacemos un muestreo aleatorio de 100 plantas de esta población.

```{r}
plantas <- matrix(c(12, 18, 28, 42), nrow = 2, ncol = 2, byrow = T)
dimnames(plantas) <- list(c("R", "NR"), c("S", "T"))
plantas
```

+----------------+-------------------+------------------+-------------+
|                | S                 | T                | **Total**   |
+================+===================+==================+=============+
| **R**          | 12                | 18               | 30          |
+----------------+-------------------+------------------+-------------+
| **NR**         | 28                | 42               | 70          |
+----------------+-------------------+------------------+-------------+
| **Total**      | 40                | 60               | 100         |
+----------------+-------------------+------------------+-------------+

Vamos a corroborar las hipótesis antes generadas:

1. $H_0: P(R|S) = P(R|T) = \frac{12}{40} = \frac{18}{60} = 0.30$

2. $H_0: P(NR|S) = P(NR|T) = \frac{28}{40} = \frac{42}{60} = 0.70$

3. $H_0: P(S|R) = P(S|NR) = \frac{12}{30} = \frac{28}{70} = 0.40$

4. $H_0: P(T|R) = P(T|NR) = \frac{18}{30} = \frac{42}{70} = 0.30$

Sin embargo, con la hipótesis 5.

5. $H_0: P(R|S) = \frac{12}{40} = 0.40$ y $H_0: P(NR|S) = \frac{28}{40} = 0.70$.

### Cuestiones acerca de las columnas y filas

El hecho de que la tabla anterior muestre la independencia vista tanto por medio de las filas o columnas no es casualidad, como se demuestra en la siguiente tabla.

+----------------+-------------------+------------------+-------------+
|                |                   |                  | **Total**   |
+================+===================+==================+=============+
|                | a                 | b                | a + b       |
+----------------+-------------------+------------------+-------------+
|                | c                 | d                | c + d       |
+----------------+-------------------+------------------+-------------+
| **Total**      | a + c             | b + d            |             |
+----------------+-------------------+------------------+-------------+

Entonces,

\begin{align}
\frac{a}{c} = \frac{b}{d}
\end{align}

si y solo si

\begin{align}
\frac{a}{b} = \frac{c}{d}
\end{align}

Otra forma en la que esto se puede expresar es

\begin{align}
\frac{a}{a+c} = \frac{b}{b+d}
\end{align}

si y solo si

\begin{align}
\frac{a}{a+b} = \frac{c}{c+d}
\end{align}

Otra cuestion es que si $a$, $b$, $c$ y $d$ son números positivos, entonces

\begin{align}
\frac{a}{a+c} > \frac{b}{b+d}
\end{align}

si y solo si

\begin{align}
\frac{a}{a+b} > \frac{c}{c+d}
\end{align}

## Prueba exacta de Fisher

Con esta prueba se encuentra la probabilidad de que la tabla de contingencia que tengamos, haya surgido por mero azar, dado que las probabilidades marginales de la tabla son fijas. Se utiliza especialmente con muestras pequeñas. La fórmula para calcular nuestro valor es la siguiente:

\begin{align}
p = \frac{\binom{a+b}{a}\binom{c+d}{c}}{\binom{n}{a+c}} = \frac{(a+b)!(c+d)!(a+c)!(b+d)!}{a! \space b! \space c! \space d!  \space n!}
(\#eq:fisher)
\end{align}

Donde $\binom{n}{k}$ es el coeficiente binomial ($_{n}C_{k}$). Para recordar este coeficiente aquí tenemos la fórmula.

\begin{equation}
_{n}C_{k} = \frac{n!}{k!(n-k)!}
(\#eq:binc2)
\end{equation}

Por ejemplo, para el primer y segundo coeficiente binomial obtendríamos lo siguiente:

\begin{align}
_{a+b}C_{a} = \frac{a+b!}{a!(a+b-a)!} \\
_{a+b}C_{a} = \frac{c+d!}{c!(c+d-c)!} 
\end{align}

Y para el último coeficiente, sería algo así:

\begin{align}
_{n}C_{a+c} = \frac{n!}{a+c!(n-a+c)!} 
\end{align}

Cuando hacemos una prueba exacta de Fisher para prubar una hipótesis nula contra una hipótesis alternativa direccional, necesitamos encontrar la probabilidad de todas las tablas de datos (teniendo los mismos margenes que la tabla observada) que provean evidencia al menos tan fuerte en contra de $H_0$, en la dirección predicha por la $H_A$, como la tabla observada.

Posteriormente calculamos el valor-*p* como la suma de las probabilidades de obtener tablas tan extremas como las obtenidas, si la $H_0$ es verdad. 

Afortundamente no tenemos que buscar los valores de todas las tablas posibles una por una y en su lugar podemos utilizar el comando `fisher.test()` que viene incluido en `R`.

>**Ejemplo:** La oxigenación extracorpórea por membrana (ECMO) es un procedimiento con el potencial de salvar vidas de bebés recién nacidos que sufren de una falla respiratoria severa. En un experimento se trataron a 29 bebés recién nacidos con ECMO y a 10 bebés recién nacidos con terapia médica convencional (CMT).

```{r}
#Creamos nuestra matriz de datos.
Tratamientos <- matrix(c(4, 1, 6, 28), nrow = 2, ncol = 2, byrow = T)
dimnames(Tratamientos) <- list(c("Muerto", "Vivo"), c("CMT", "ECMO"))
Tratamientos
```

+----------------+-------------------+------------------+--------------+
|                | CMT               | ECMO             | **Total**    |
+================+===================+==================+==============+
| **Muerto**     | 4                 | 1                | 5            |
+----------------+-------------------+------------------+--------------+
| **Vivo**       | 6                 | 28               | 34           |
+----------------+-------------------+------------------+--------------+
| **Total**      | 10                | 29               | 39           |
+----------------+-------------------+------------------+--------------+

```{r}
fisher.test(Tratamientos)
```

Como podemos ver, el $valor-p = 0.01102$ lo que quiere decir que rechazamos la $H_0$ y aceptamos la $H_A: P(Muerto|ECMO) < P(Muerto|CMT)$.

```{r}
fisher.test(Tratamientos)
```

Para cambiar la direccionalidad de nuestra hipótesis basta con que agreguemos el argumento `alternative = "two.sided"` para una $H_A$ no direccional y `alternative = "less"` o `alternative = "greater"` para una $H_A$ direccional.

## Tablas de contingencia $r \times k$

En esta sección consideraremos tablas de contingencia más grandes, con $r$ filas y $k$ columnas. Veamos el siguiente ejemplo.

>**Ejemplo:** Ecólogos que estudiaron los hábitats reproductivos del Chorlo Llanero (*Charadrius montanus*) durante 3 años y anotaron en dónde es que anidan. Encontraron 66 nidos en zonas agricolas (ZA), 67 en pastizales con perritos de las praderas (PP) y otros 20 en praderas (P). La siguiente tabla muestra las elecciones a través de los años.

```{r}
chorlos <- matrix(c(21, 19, 26, 17, 38, 12, 5, 6, 9), nrow = 3, ncol = 3, byrow = T)
dimnames(chorlos) <- list(c("Zona Agricola (ZA)", "Pastizal con Perritos (PP)", "Praderas (P)"), c("2004", "2005", "2006"))
chorlos
```

+--------------------------------+----------+----------+----------+-----------+
|                                | **2004** | **2005** | **2006** | **Total** |
+--------------------------------+----------+----------+----------+-----------+
| **Zona Agricola (ZA)**         | 21       | 19       | 26       | 66        |
+--------------------------------+----------+----------+----------+-----------+
| **Pastizal con Perritos (PP)** | 17       | 38       | 12       | 67        |
+--------------------------------+----------+----------+----------+-----------+
| **Praderas (P)**               | 5        | 6        | 9        | 20        |
+--------------------------------+----------+----------+----------+-----------+
| **Total**                      | 43       | 63       | 47       | 153       |
+--------------------------------+----------+----------+----------+-----------+

En este caso, podemos transformar los valores absolutos en relativos haciendo uso del total que se encuentra en las columnas. Por ejemplo, en el caso de *2004* y la *ZA* tendríamos algo como $\frac{21}{43} = 0.488$ y así sucesivamente.

+--------------------------------+----------+----------+----------+
|                                | **2004** | **2005** | **2006** |
+--------------------------------+----------+----------+----------+
| **Zona Agricola (ZA)**         | 48.8     | 30.2     | 55.3     |
+--------------------------------+----------+----------+----------+
| **Pastizal con Perritos (PP)** | 39.5     | 60.3     | 25.5     |
+--------------------------------+----------+----------+----------+
| **Praderas (P)**               | 11.6     | 9.5      | 19.1     |
+--------------------------------+----------+----------+----------+
| **Total**                      | 99.9     | 100      | 99.9     |
+--------------------------------+----------+----------+----------+

Algunos totales no dan el 100 debido al redondeo. Podemos ver en la figura \@ref(fig:Ej2a) las proporciones de cada una de las áreas de anidamiento correspondientes con cada año. Estos porcentajes que tenemos en la tabla son nuestras probabilidades condicionales, es decir $P(ZA|2004) = 0.488$, $P(PP|2004) = 0.395$, $P(P|2004) = 0.116$ y así sucesivamente...

```{r Ej2a, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align='center', fig.align="center", fig.cap="Gráfica con las proporciones de las zonas de anidamiento del Chorlo Llanero."}
graph <- data.frame(Año = c(rep("2004", 3), rep("2005", 3), rep("2006", 3)), Zona = rep(c("Zona Agricola (ZA)", "Pastizal con Perritos (PP)", "Praderas (P)"), 3), Nidos = c(48.8, 39.5, 11.6, 30.2, 60.3, 9.5, 55.3, 25.5, 19.1))

ggplot(graph, aes(fill = reorder(Zona, Nidos), y = Nidos, x = Año)) + 
  geom_bar(position = position_fill(reverse = F), stack = "dodge", stat = "identity",  color = "Grey5", width = 0.6) +
  scale_fill_grey(start = 0.8, end = 0.4) +
  xlab("") +
  ylab("Proporción") +
  labs(fill = "Lugar de anidamiento") +
  theme_classic()
```

Para esto simplemente aplicamos la fórmula de Chi-cuadrada.

\begin{align}
\sum_{r \times k} = \frac{(o_i - e_i)^2}{e_i}
(\#eq:chirk)
\end{align}

Donde $r \times k$ son todas las céludas de nuestra tabla de contingencia. Los valores $e$ se calculan con la fórmula vista anteriormente \@ref(eq:e). Para los grados de libertad $df$ utilizaríamos la siguiente fórmula:

\begin{align}
df = (r-1)(k-1)
(\#eq:dfrk)
\end{align}

Nuestra $H_0$ para los Chorlos sería que la preferencia de anidamiento es igual en todos los años y la $H_A$ sería que son distintas.

\begin{equation*}
H_0:
\begin{Bmatrix}
P(ZA|2004) = P(ZA|2005) = P(ZA|2006) \\
P(PP|2004) = P(PP|2005) = P(PP|2006) \\
P(P|2004) = P(P|2005) = P(P|2006)
\end{Bmatrix}
\end{equation*}

Igual que con la tabla de contingencia de 2x2, multiplicamos la probabilidad marignal por el total para obtener el valor esperado. Es decir, del total chorlos en la Zona Agricola (ZA) $\frac{66}{153} \times 43 = 18.55$ y así sucesivamente.

+--------------------------------+------------+------------+------------+-----------+
|                                | **2004**   | **2005**   | **2006**   | **Total** |
+--------------------------------+------------+------------+------------+-----------+
| **Zona Agricola (ZA)**         | 21 (18.55) | 19 (21.18) | 26 (20.27) | 66        |
+--------------------------------+------------+------------+------------+-----------+
| **Pastizal con Perritos (PP)** | 17 (18.83) | 38 (27.59) | 12 (20.58) | 67        |
+--------------------------------+------------+------------+------------+-----------+
| **Praderas (P)**               | 5 (5.62)   | 6 (8.24)   | 9 (6.14)   | 20        |
+--------------------------------+------------+------------+------------+-----------+
| **Total**                      | 43         | 63         | 47         | 153       |
+--------------------------------+------------+------------+------------+-----------+

Ahora simplemente aplicamos la fórmula de Chi-cuadrada para obtener nuestro estadístico $\chi_s^2$. 

\begin{equation}
\chi_s^2 = \frac{(21-18.55)^2}{18.55} + \frac{(19-21.18)^2}{21.18} + \cdots + \frac{(9-6.14)^2}{6.14} = 14.09
\end{equation}

Nuestros $df$ son los siguientes, dado que $r = 3$ y $k = 3$:

\begin{equation}
df = (3-1)(3-1) = 4
\end{equation}

Si buscamos el valor de tablas, vemos que el valor-*p* se encuentra entre 0.01 y 0.001. Pero para facilitarnos la vida, simplemente ingresamos nuestra variable `chorlos` que creamos previamente a la función `chisq.test()` y obtenemos nuestro resultado. Podemos corroborar que el valor de $\chi^2$ calculado coincide al igual que los $df$. Nuestro $valor-p = 0.007$ por lo tanto, $valor-p < 0.01$, tenemos evidencias significativas con un $\alpha = 0.01$ de de que los Chorlos Llaneros cambiaron de sitio de anidación. Para estos casos, nuestra $H_A$ siempre será no direccional.

```{r}
chisq.test(chorlos)
```

Al igual que con las tablas de contingencia 2x2, las tabla $r \times k$ pueden ser vistas bajo dos contextos.

1. $k$ muestras independientes; una variable categórica observada con $r$ categorías

2. Una muestra; dos variables categóricas observadas --- una con $k$ categorías y otra con $r$ categorías.

Y al igual que las tablas 2x2, el cálculo del valor $\chi^2$ es el mismo para ambos contexto pero la interpretación de las hipótesis cambia.

## Intervalos de confianza para la diferencia entre probabilidades