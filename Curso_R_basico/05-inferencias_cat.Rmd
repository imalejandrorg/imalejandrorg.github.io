---
output:
  bookdown::html_document2:
    fig.caption: yes
editor_options: 
  markdown: 
    wrap: sentence
---

# Inferencia de datos categóricos

```{r include=FALSE}
library(knitr)
library(bookdown)
library(tidyverse)
library(kableExtra)
library(ggthemes)
library(cowplot)
library(ggpubr)
library(latex2exp)
library(kableExtra)
library(broom)
```

## Distribuciones de una muestra

En esta sección consideraremos **variables categóricas**, es decir, variables que solamente tienen dos posibles valores, y su distribución muestral de la proporción de la muestra. Normalmente, al tomar muestras de una población dicotómica grande, un estimado de la proporción, $p$, es la muestra de la proporción $\hat{p} = \frac{x}{n}$, donde $x$ es el número de observaciones en la muestra que cumplen con el atributo de interés, y $n$ es el tamaño de muestra.

La proporción de Wilson ajustada a la muestra, $\tilde{p}$, es otro estimado que utiliza la fórmula \@ref(eq:wilson). Esto equivale a sesgar la estimación hacia el valor 1/2. 

\begin{equation}
\tilde{p} = \frac{x + 2}{n + 4}
(\#eq:wilson)
\end{equation}

La distribución binomial determina la distribución muestral de $\tilde{P}$. Veamos cómo funciona esto con un ejemplo.

>**Ejemplo:** En una región de Estados Unidos, el 17% de las máquinas dispensadoras de bebidas están contaminadas por la bacteria *Chryseobacterium meningosepticum*. Imaginemos que examinamos una muestra de dos máquinas dispensadoras. La probabilidad de tener dos máquinas contaminadas es $0.17 * 0.17 = 0.0289$, la probabilidad de que ninguna este contaminada es de $1-0.17 * 1-0.17$ y la probabilidad de que una este contaminada y la otra no es $0.17 * (1-0.17) + 0.17 * (1-0.17)$.

Una muestra que contenga cero máquinas contaminadas, $\tilde{p} = \frac{0+2}{2+4} = 0.33$ ocurre con una probabilidad de 0.6889, una muestra con una máquina contaminada, $\tilde{p} = \frac{1+2}{2+4} = 0.5$ ocurre con una probabilidad de 0.2822 y una muestra con dos máquinas contaminadas, $\tilde{p} = \frac{2+2}{2+4} = 0.67$ ocurre con una probabilidad de 0.0289. Por ende, hay un 68.89% de probabilidad de que $\tilde{P}$ sea igual a 0.33, un 28% de que $\tilde{P}$ sea igual a 0.5 y 3% de que $\tilde{P}$ sea igual a 0.67.

Imaginemos ahora que nuestra muestra pasa de $n = 2$ a $n = 20$, para encontrar la probabilidad de cuántas máquinas podríamos esperar que estén contaminadas en nuestra muestra, acudimos a la distribución binomial. Por ejemplo, para calcular que 5 de las 20 máquinas están contaminadas usamos $p = 0.17$ y $n = 20$.

```{r}
dbinom(5, 20, 0.17)
```

Como vemos, la probabilidad de obtener 5 máquinas contaminadas es 0.1345, ahora, usando $\tilde{P}$, una muestra con 5 máquinas contaminadas sería $\tilde{p} = \frac{5+2}{20+4} = 0.2917$, por lo que $P(\tilde{P} = 0.2917) = 0.1345$. Con la distribución binomial, podemos determinar toda la distribución muestral de $\tilde{P}$. 

Por ejemplo, podemos preguntar *¿Cuál es la probabilidad de que no más de 5 máquinas estén contaminadas?*

```{r}
pbinom(5, 20, 0.17)
```

Como vemos, la probabilidad de que no más de 5 máquinas estén contaminadas es de 0.8902245. Y como $\tilde{p} = \frac{5+2}{20+4} = 0.2917$ entonces $P(\tilde{P} \leq 0.2917) = 0.8902$. La distribución muestral de $\tilde{P}$ se puede utilizar para predecir cuánto error de muestreo esperar en nuestro estimado. De igual manera, entre mayor sea nuestro $n$ mayor posibilidades hay de que $\tilde{P}$ se encuentre cercano a $p$. 

Para la construcción de **intervalos de confianza** de la proporción de una población, necesitamos encontrar el error estándar de $\tilde{P}$. Para eso utilizamos la siguiente fórmula (para intervalos al 95%).

\begin{equation}
SE_\tilde{p} = \sqrt{\frac{\tilde{p}(1-\tilde{p})}{n + 4}}
(\#eq:pse)
\end{equation}

Posteriormente, realizamos el intervalo de confianza correspondiente con la siguiente fórmula (esto para un intervalo de confianza al 95%).

\begin{equation}
\tilde{p} \pm 1.96 \times SE_{\tilde{p}}
(\#eq:pic)
\end{equation}

Al igual que con otros métodos, podemos construir un intervalo de confianza unilateral si así lo deseamos. Para eso podemos utilizar la función `qnorm()` en la cuál indicamos el valor de densidad (o probabilidad) que deseamos y así obtener un valor Z.

```{r}
qnorm(0.95, 0, 1)
```

Como podemos ver, para casos de intervalos de confianza unilaterales al 95% utilizaríamos un multiplicador de 1.645.

\begin{equation}
\tilde{p} \pm 1.645 \times SE_{\tilde{p}}
(\#eq:pic2)
\end{equation}

Las fórmulas para intervalos de confianza generales son las siguientes:

\begin{equation}
\tilde{p} \pm z_{\alpha/2} \times SE_{\tilde{p}}
(\#eq:pic2)
\end{equation}

\begin{equation}
\tilde{p} = \frac{x + 0.5(z^2_{\alpha/2})}{n + z^2_{\alpha/2}}
(\#eq:wilson2)
\end{equation}

\begin{equation}
SE_\tilde{p} = \sqrt{\frac{\tilde{p}(1-\tilde{p})}{n + z^2_{\alpha/2}}}
(\#eq:pse2)
\end{equation}


## Prueba de Chi-cuadrada

Una **prueba de bondad de ajuste** se utiliza para ver la compatibilidad de los datos con una distribución o $H_0$ específica. Una de las más utilizadas es la **prueba de $\chi^2$** (léase chi-cuadrada). Para esto se utilizan frecuencias absolutas de nuestros datos. Para cada nivel de categoría, $i$, dejamos que $o_i$ represente la frecuencia observada y $e_i$ la frecuencia esperada, es decir, la frecuencia que esperaríamos obtener bajo la $H_0$. Las frecuencias esperadas $e_i$ se obtienen multiplicando las probabilidades dadas por la $H_0$ por $n$. 
Posteriormente utilizamos la fórmula \@ref(eq:chi) para calcular nuestro estadístico de prueba.

\begin{equation}
\chi^2 = \sum_{i = 1}^{k}\frac{(o_i - e_i)^2}{e_i}
(\#eq:chi)
\end{equation}

Donde $k$ es el número total de categorías e $i$ es la *i*-ésima observación.

>**Ejemplo:** Después de seis meses de un incendio, los investigadores muestrearon una parcela de 3000 acres al rededor del área quemada. La dividieron en cuatro regiones: (1) el área cercana al centro del incendio, (2) el área interior cercana al incendio, (3) el área exterior cercana al incendio y (4) área fuera de la zona quemada. La $H_0$ es que los venados no muestran preferencia por alguna de las áreas. La $H_A$ es que muestran cierta preferencia por alguna de las áreas.

```{r}
Area <- c(520, 210, 240, 2030)
Zona <- c("Área interior", "Área exterior", "Borde exterior", "No quemado")
Proporcion <- round(Area/sum(Area), 3)

Datos <- data.frame(Zona, Area, Proporcion)
```

```{r Ejemplo1, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
Datos %>% 
  knitr::kable("html", align = c("c", "c"), caption = "Áreas quemadas y no quemadas", col.names = c("Zona", "Área", "Proporción")) %>%
  kableExtra::kable_classic(lightable_options = "striped", full_width = F) %>% 
  column_spec(1:3, width_min = "4cm")
```

Si la $H_0$ es verdadera, entonces

\begin{aligned}
H_0: P(Área \space interior) = \frac{520}{3000} = 0.173 \\
P(Área \space exterior) = \frac{210}{3000} = 0.070 \\
P(Borde \space  exterior) = \frac{240}{3000} = 0.080 \\
P(No \space quemado) = \frac{2030}{3000} = 0.677
\end{aligned}

Entonces la $H_A$ sería

\begin{aligned}
H_A: P(Área \space interior) \ne 0.173 \\
P(Área \space exterior) \ne 0.070 \\
P(Borde \space  exterior) \ne 0.080 \\
P(No \space quemado) \ne 0.677
\end{aligned}

Los investigadores encontraron 75 venados en el área, distribuidos en distintas zonas como se muestra a continuación.

```{r}
Venados <- c(2, 12, 18, 43)
Datos <- data.frame(Datos, Venados)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align='center', fig.cap="Zonas de avistamientos de venados, $n = 75$."}
ggplot(Datos, aes(reorder(Zona, Venados), Venados)) + geom_bar(stat = "identity", color = "Gray20", fill = "Gray80", width = 0.7) +
  xlab("Zona") +
  ylab("No. de venados") +
  theme_classic()
```

```{r Ejemplo1a, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
Datos %>% 
  knitr::kable("html", align = c("c", "c"), caption = "Áreas quemadas y no quemadas y el número de venados observados", col.names = c("Zona", "Área", "Proporción", "No. de venados")) %>%
  kableExtra::kable_classic(lightable_options = "striped", full_width = F) %>% 
  column_spec(1:3, width_min = "4cm")
```


Para este caso, las probabilidades estimadas (denotadas como $\hat{p}$) son

\begin{align}
\hat{P}(Área \space interior) = \frac{2}{75} = 0.027 \\
\hat{P}(Área \space exterior) = \frac{12}{75} = 0.160 \\
\hat{P}(Borde \space  exterior) = \frac{18}{75} = 0.240 \\
\hat{P}(No \space quemado) = \frac{43}{75} = 0.573
\end{align}

Estas las podemos calcular fácilmente.

```{r}
Prop_venados <- round(Venados/sum(Venados), 3)
Datos <- data.frame(Datos, Prop_venados)
```

```{r Ejemplo1b, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
Datos %>% 
  knitr::kable("html", align = c("c", "c"), caption = "Áreas quemadas y no quemadas y el número de venados observados con su proporción", col.names = c("Zona", "Área", "Proporción esperada", "No. de venados", "Proporción observada")) %>%
  kableExtra::kable_classic(lightable_options = "striped", full_width = F) %>% 
  column_spec(1:3, width_min = "3.5cm")
```

Como podemos ver, las proporciones observadas $\hat{P}$ difieren de las que esperaríamos en el modelo de la $H_0$.

```{r Ejemplo1c, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align='center', fig.cap="Valores observados contra esperados en las proporciones de venados en zonas quemadas."}
Condicion <- c(rep("Esperado", 4), rep("Observado", 4))
Zona1 <- rep(c("Área interior", "Área exterior", "Borde exterior", "No quemado"), 2)
Prop <- c(Proporcion, Prop_venados)

graph <- data.frame(Condicion, Zona1, Prop)

ggplot(graph, aes(fill = reorder(Zona1, Prop), y = Prop, x = Condicion)) + 
  geom_bar(position = position_fill(reverse = T), stack = "dodge", stat = "identity",  color = "Grey5", width = 0.6) +
  scale_fill_grey(start = 0.2, end = 0.8) +
  xlab("") +
  ylab("Proporción") +
  labs(fill = "Zona") +
  theme_classic()
```

Ahora, para aplicar la fórmula de $\chi^2$ necesitamos los valores absolutos de nuestros datos, para esto simplemente multiplicamos la probabilidad calculada por la $H_0$, $p * n$.

```{r}
#Usamos la función sum() para sumar todos los valores de la variable "Venados".
Venados_esperados <- Proporcion * sum(Datos$Venados) 
Venados_esperados
```

Como podemos ver, los valores son aproximadamente 13, 5.25, 6 y 50.78. Ahora simplemente aplicamos la fórmula para nuestros datos.

\begin{align}
\chi_s^2 = \frac{(2-13)^2}{13} + \frac{(12-5.25)^2}{5.25} + \frac{(18-6)^2}{6} + \frac{(43-50.78)^2}{50.78} = 43.2
\end{align}

Ahora tenemos que considerar la distribución nula de $\chi_s^2$, que es la distribución muestral que se sigue en caso de que nuestra $H_0$ sea verdadera. Esta distribución muestral sigue la distribución de chi-cuadrada $\chi^2$ cuando el tamaño de muestra es suficientemente grande. La forma de la distribución de $\chi^2$ depende de los grados de libertad.

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.align='center', fig.cap="Distribución de $\\chi^2$ con $df = 5$ en azul, $df = 8$ en rojo y $df = 10$ en verde."}

ggplot(data.frame(x = c(0, 30)), aes(x = x)) +
  stat_function(fun = dchisq, args = list(df = 5), size = 0.6, color = "blue") +
  stat_function(fun = dchisq, args = list(df = 8), size = 0.6, color = "red") +
  stat_function(fun = dchisq, args = list(df = 10), size = 0.6, color = "darkgreen") +
  geom_text(aes(x = 20, label = "df = 5", y = 0.1), color = "blue") +
  geom_text(aes(x = 20, label = "df = 8", y = 0.09), color = "red") +
  geom_text(aes(x = 20.2, label = "df = 10", y = 0.08), color = "darkgreen") +
  scale_y_continuous(breaks = NULL) +
  ylab("") +
  xlab("") +
  theme_minimal_hgrid(color = "black")

```

Al igual que las demás distribuciones de probabilidad en `R`, tenemos una serie de comandos para encontrar los valores de una distribución de chi-cuadrada fácilmente.

-`dchisq()` nos da un valor de densidad en determinado punto de la distribución de $\chi^2$.

-`pchisq()` nos da un valor de densidad acumulado hasta cierto punto en la distribución de $\chi^2$ (área debajo de la curva).

-`qchisq()` toma el valor de densidad que le ponemos como primer argumento y nos da como regreso un número cuya densidad acumulada empate con el valor de densidad ingresado.

-`rchisq()` genera cierta cantidad de número aleatorios de acuerdo al valor de densidad.

Sin embargo en este caso, en lugar de contar con el argumento `n` para el tamaño de muestra, contamos con otro argumento `df` para los grados de libertad.

Por ejemplo, supongamos que quisiéramos encontrar el valor crítico $\chi_{5,0.05}^2$ cuando $df = 5$, para esto utilizamos la función `qchisq()`.

```{r}
qchisq(0.95, 5)
```

Como podemos ver, el valor crítico es 11.07. Esto corresponde a un área de 0.05 por encima de la cola de la distribución de $\chi^2$.

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

ggplot(data.frame(x = c(0, 30)), aes(x = x)) +
  stat_function(fun = dchisq, args = list(df = 5), geom = "area", fill = "lightblue", xlim = c(11.07,30)) +
  stat_function(fun = dchisq, args = list(df = 5), size = 0.6) +
  geom_vline(aes(xintercept = 11.07), linetype = "dashed", size = 0.35) +
  geom_text(aes(x = 15, y = 0.03, label = "Área = 0.05")) +
  geom_text(aes(x = 5, y = 0.03, label = "Área = 0.95")) +
  scale_y_continuous(breaks = NULL) +
  scale_x_continuous(limit = c(0, 30), breaks = c(0, 5, 11.07, 15, 20, 25, 30), labels = c("0" = "0", "5" = "5",  "11.07" = parse(text = TeX("$\\chi_{5, 0.025}^2$")), "15" = "15", "20" = "20", "25" = "25", "30" = "30")) +
  ylab("") +
  xlab("") +
  theme_minimal_hgrid(color = "black")

```

El cálculo de los grados de libertad $df$ para una distribución de $\chi^2$ depende del número de categorías, $k$.

\begin{align}
df = k - 1
(\#eq:chidf)
\end{align}

Siguiendo el ejemplo de los venados, en este caso tenemos $k = 4$ por lo que $df = 4 - 1 = 3$. Ya que el valor que habíamos obtenido de nuestra fórmula de $\chi_s^2 = 43.2$, buscaremos el área debajo de la curva correspondiente a este valor.

```{r}
pchisq(43.2, 3, lower.tail = F)
```

Como podemos ver el resultado es extremadamente pequeño y nuestro $valor-p < 0.0001$ por lo que tenemos evidencia para rechazar la $H_0$ y aceptar la hipótesis de que los venados prefieren ciertas zonas sobre otras. La prueba de $\chi^2$ se puede utilizar para cualquier número de categorías $k$.

Ahora todo esto se facilita gracias a la función `chisq.test()` que viene incluida en `R`.

Para realizar la prueba de Chi-cuadrada con esta función, lo único que necesitamos es una variable con el valor absoluto de nuestras observaciones y otra con los valores  relativos esperados como los de la tabla \@ref(tab:Ejemplo1d). 

```{r}
chisq.test(Datos$Venados, Datos$Propocion)
```

Estos valores los podemos obtener de la matriz de datos que habíamos creado previamente, simplemente los seleccionamos con  el símbolo `$` seguido del nombre de la variable (`$Venados` y `$Proporcion`, en mí caso).

```{r Ejemplo1d, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
Datos %>% 
  dplyr::select(-Zona, -Area, -Prop_venados) %>% 
  knitr::kable("html", align = c("c", "c"), caption = "Datos utilizados por la función `chisq.test()` en R", col.names = c("Proporción esperada", "No. de venados")) %>%
  kableExtra::kable_classic(lightable_options = "striped", full_width = F) %>% 
  column_spec(1:2, width_min = "5.2cm")
```

### Hipótesis compuestas y direccionales

Hay que darnos cuenta que en el ejemplo de los venados, nuestras hipótesis son **hipótesis compuestas**, es decir, hacen múltiples afirmaciones, a diferencia de las hipótesis que hacíamos en las pruebas de $t$ ($H_0: \mu_1 = \mu_2$). Las primeras tres afiramciones de nuestra hipótesis nula $H_0$ son independientes ($P(Área \space interior) = 0.173$, $P(Área \space exterior) = 0.070$, $P(Borde \space  exterior) = 0.080$) pero nuestra última afirmación ($P(No \space quemado) = 0.677$) es **dependiente** de las demás afirmaciones realizadas. Cuando esto ocurre, la hipótesis alternativa es necesariamente no direccional. Otra cosa interesante es que cuando se rechaza la $H_0$, la prueba no nos dice la dirección de la conclusión.

En cambio, cuando una variable es dicotómica, la $H_0$ no es compuesta y por lo tanto, alternativas direccionales o conclusiones direccionales no suponen un problema. Para una variable dicotómica, una prueba de hipótesis direccional de Chi-cuadrada se realizaría de la misma manera que en pruebas pasadas. 

1. Primero elegimos la direccionalidad y corroboramos que los datos se desvían de la $H_0$ en la dirección especificada por la $H_A$. Si es así realizamos el siguiente paso.

2. Encontramos el valor-*p*, el cuál será la mitad de lo que sería si nuestra $H_A$ fuese no direccional.