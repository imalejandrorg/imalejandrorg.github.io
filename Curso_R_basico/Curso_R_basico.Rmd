--- 
title: "Curso de R básico"
author: "Alejandro Ruiz-García"
date: "15/3/2021"
site: bookdown::bookdown_site
documentclass: book
bibliography:
- book.bib
- packages.bib
biblio-style: apalike
csl: apa.csl
link-citations: yes
description: Curso de R cubriendo los aspectos básicos para el análisis de datos biológicos.
---

# Requisitos {-}

Placeholder


## Descarga de R y RStudio

<!--chapter:end:index.Rmd-->


# Introducción a R

Placeholder


## Interfaz
## Creando nuestro primer proyecto
## Objetos y variables
## Instalar paquetes
## Importar datos a R
## Comentarios
## Exportar datos
## Pedir ayuda

<!--chapter:end:01-intro.Rmd-->


# Estadística descriptiva

Placeholder


## Medidas de tendencia central
### Media en R
### Mediana en R
### La función `summary`
### Visualización básica de datos
### Valores atípicos
## Medidas de dispersión
### Rango en R
### Desviación estándar en R
## Medidas de posición
## El uso de la librería `dplyr`

<!--chapter:end:02-estadisticadesc.Rmd-->

---
title: "Análisis de Varianza (ANOVA)"
author: "Alejandro Ruiz-García"
date: "16/3/2021"
output:
  bookdown::html_document2:
    fig.caption: yes
---

# Análisis de Varianza (ANOVA)
```{r include=FALSE}
library(knitr)
library(bookdown)
library(vegan)
library(tidyverse)
library(kableExtra)
library(knitr)
```

Para realizar un **análisis de varianza** o **ANOVA** es necesario cumplir con ciertos supuestos. Estos supuestos son similares para otro tipo de pruebas y se encuentran descritas en la sigueinte lista:

- Distribución normal de los datos.
- Homocedasticidad (varianzas iguales).
- Datos independientes.

La distribución normal y la homocedasticidad son hasta cierto punto flexibles. Sin embargo, el ANOVA es sumamente sentitivo a muestras no independientes. Pese a su nombre, el análisis de varianza en realidad busca **diferencias en las medias ($\mu$)** de las muestras.

Antes de hacer el ANOVa debemos buscar una manera de comprobar la distribución normal y la homocedasticidad de los datos. Esto es relativamente sencillo de hacer.

## Prueba de normalidad
Una de las pruebas de normalidad más utilizadas es la prueba de Shapiro-Wilk. El resultado de la prueba de Shapiro-Wilk es un valor-*p* que se puede interpretar de la siguiente manera:

- Valor-*p* $<$ 0.01: No normalidad.
- Valor-*p* $<$ 0.05: No normalidad.
- Valor-*p* $\ge$ 0.05: Sin evidencia concluyente de no normalidad.

Usualmente un valor-*p* $<$ 0.05 es suficiente para indicar que nuestros datos no se distribuyen de manera normal. Esta base de datos incluye 2 variables, los valores del peso y el tratamiento que recibieron las plantas.

Para esta ocasión vamos a trabajar con la base de datos `PlantGrowth` que viene incluida en R.
```{r}
data("PlantGrowth")
```

Vamos a realizar una gráfica de nuestros datos para darnos una idea de su comportamiento.
```{r fig.align = "center", fig.cap = "Gráfica con los distintos tratamientos."}
library(ggplot2)

ggplot(PlantGrowth) + geom_point(aes(group, weight, color = group)) + 
  xlab("Grupo") +
  ylab("Peso") +
  scale_color_discrete(name = "Tratamientos", labels = c("Control", "Tratamiento 1", "Tratamiento 2")) +
  theme_classic()
```

Otra forma de visualizar los datos es con un boxplot que puede ir dándonos idea más o menos de cómo se distribuyen nuestros datos.
```{r fig.align = "center", fig.cap = "Graficos de boxplot para visualización de las distribuciones de los datos."}
library(ggplot2)

ggplot(PlantGrowth) + geom_boxplot(aes(group, weight, fill = group)) + 
  xlab("Grupo") +
  ylab("Peso") +
  scale_fill_discrete(name = "Tratamientos", labels = c("Control", "Tratamiento 1", "Tratamiento 2")) +
  theme_classic()
```

Computar la prueba de normalidad de Shapiro-Wilk sumamente sencillo y se hace con la función `shapiro_test()` de la librería `rstatix`. Para esto primero tenemos que agrupar nuestros datos por tratamientos con la función `group_by()` del paquete de `dplyr`. 
```{r}
library(tidyverse)
library(rstatix)

PlantGrowth %>% group_by(group) %>% shapiro_test(weight) #Agrupamos los datos por tratamiento.
```
Tanto el control como los dos tratamientos tienen un valor-*p* $>$ 0.05, lo que indica que se distribuyen de manera normal. El estadístico que obtenemos se conoce como $W$ y entre más cercano sea su valor a 1 más evidencia existe de que se trata de datos que se distribuyen de manera normal.

Otra opción es realizar la prueba de Shapiro-Wilk con la función integrada en R, de nombre bastante similar, llamada `shapiro.test()`. Para esta prueba no es necesario agrupar los datos por tratamiento.
```{r}
PlantGrowth$weight %>% shapiro.test
```

Como podemos ver, el valor-*p* = 0.8915, lo que indica que nuestros datos se distribuyen de manera normal.

Algo importante a tener en consideración es que para muestras con $n > 50$ es recomendable utilizar otra prueba ya que la prueba de Shapiro-Wilk es sensible a pequeñas desviaciones de la normalidad para muestras grandes. Una alternativa es la utilización de **gráficos Q-Q** o **Q-Q plot**. Los gráficos Q-Q nos muestran la correlación que existe entre una muestra dada y la distribución normal. Utilizaremos la librería `ggpubr` y la función `ggqqplot()`.
```{r fig.align = "center", fig.cap = "Gráfico Q-Q que muestra la distribución normal de datos."}
library(ggpubr)

ggqqplot(PlantGrowth$weight) +
  xlab("Teórico") +
  ylab("Muestra")
```

Este gráfico nos muestra una distribución normal teórica vs. la de nuestros datos. Como podemos ver, todos los puntos caen dentro del intervalo de confianza al 95% de la recta, lo que quiere decir que nuestros datos se distribuyen de manera normal. Esto confirma los resultados obtenidos con la prueba de Shapiro-Wilk. Otra opción sería ver la **gráfica de densidad** para identificar la forma de la distribución.
```{r fig.align = "center", fig.cap = "Gráfico de densidad que muestra una ligera forma de campana, lo que indica una distribución normal de los datos."}
ggdensity(PlantGrowth$weight, fill = "lightblue") +
  xlab("Peso") +
  ylab("Densidad")
```


## Prueba de homocedasticidad
Para la prueba de homocedasticidad existen varias aproximaciones. En este caso veremos pruebas estadísticas, ya que existen pruebas que se pueden realizar una vez realizamos el ANOVA.

La prueba a utilizar es la prueba de Bartlett, que en R se escribe `bartlett.test()`. Es una prueba relativamente sencilla de realizar.
```{r}
bartlett.test(weight ~ group, PlantGrowth)
```

Indicamos que la variable `weight` va a ser evaluada bajo la variable `group`. Como resultados tenemos el estadístico Bartlett, los grados de libertad y el valor-*p*, que en este caso resulto ser valor-*p* $>$ 0.05 lo que significa que aceptamos la hipótesis de que nuestros datos tienen varianzas iguales. Un valor-*p* $<$ 0.05 indicaría que nuestros datos NO tienen varianzas iguales.

Otra prueba que podemos utilizar que viene en la librería `car` es la prueba de Levene. Utilizamos la función `leveneTest()`.
```{r message=FALSE, warning=FALSE}
library(car)

leveneTest(weight ~ group, PlantGrowth, mean)
```

En este caso nuestro valor-*p* es mayor a 0.05 (indicado en el outpot como `Pr(>F)`) lo que indica que no hay diferencias en las varianzas de nuestras muestras. Es importante que en nuestro último argumento (`center`) escribamos que queremos que los calculos se realicen con la media (`center = mean`). Si utilizamos la mediana, haremos una prueba modificada de Levene conocida como prueba de Brown-Forsythe, que es la prueba que realiza por defecto si no escribimos `mean`.

```{r}
leveneTest(weight ~ group, PlantGrowth)
```

Podemos ver que medida de tendencia central utilizó en la consola, después del título de la prueba. Una vez que hemos corroborado que nuestros datos presentan *homocedasticidad*, *distribución normal* y sabemos que son *independientes*, podemos proceder a hacer el ANOVA.
## 

<!--chapter:end:03-norm.Rmd-->

`r if (knitr::is_html_output()) '# References {-}'`

<!--chapter:end:06-references.Rmd-->


# Histogramas y gráficos de densidad

Placeholder


## R y `ggplot2`
### Histogramas y gráficos de densidad en R
### Histogramas y gráficos de densidad en `ggplot2`

<!--chapter:end:hist.Rmd-->


# Distribuciones de probabilidad

Placeholder


## Distribución binomial
### `dbinom`
### `pbinom`
### `qbinom`
### rbinom

<!--chapter:end:probdist.Rmd-->

